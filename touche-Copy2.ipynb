{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#r = requests.post('http://10.30.99.211:8261/gpt_small', data = \"What is better for deep learning Python or Matlab?\")\n",
    "#print (r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_a_search_request(query):\n",
    "    # return json\n",
    "    # json will be processed further\n",
    "    params = {\n",
    "            \"apikey\": \"0833a307-97d3-462a-99d9-27db400c70da\",\n",
    "            \"query\": query,\n",
    "            \"index\": [\"cw12\"],\n",
    "            \"size\": 10,\n",
    "            \"pretty\": True\n",
    "        }\n",
    "    response = requests.get(url = \"http://www.chatnoir.eu/api/v1/_search\", params = params)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"apikey\": \"0833a307-97d3-462a-99d9-27db400c70da\",\"query\": 'What is the difference between sex and love?',\"index\": [\"cw12\"],\"size\": 10,\"pretty\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_tira_2 import make_a_search_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objs_asp(model_for_extraction, input_string):\n",
    "    model_for_extraction.from_string(input_string)\n",
    "    obj1, obj2, predicates, aspects = model_for_extraction.get_params()\n",
    "    return (obj1, obj2, predicates, aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will be loaded\n",
      "loading\n",
      "extract_objects_predicates gpu 2\n",
      "in extractor get params 0\n",
      "words  [['what', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love?']\n",
      "tokens  ['What', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love', '?']\n",
      "or simple split_sent 6\n",
      "sex love\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "extr = models.extractor()\n",
    "obj1, obj2, pred, asp = extract_objs_asp(extr, \"What is the difference between sex and love?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "def read_xml(filename):\n",
    "    # convert file filename to list of tuples (number_of_topic, title_of_topic) \n",
    "    # input: filename string\n",
    "    # output: list of corresponding tuples\n",
    "    answer_list = []\n",
    "    xmldoc = minidom.parse(filename)\n",
    "    itemlist = xmldoc.getElementsByTagName('topics')\n",
    "    print(len(itemlist))\n",
    "    print(itemlist)\n",
    "    topic_list = itemlist[0].getElementsByTagName('topic')\n",
    "    print (len(topic_list))\n",
    "    for topic in topic_list:\n",
    "        tuple_for_add = tuple((topic.getElementsByTagName('number')[0].firstChild.nodeValue, topic.getElementsByTagName('title')[0].firstChild.nodeValue))\n",
    "        answer_list.append(tuple_for_add)\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7f051d0240f0>]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/notebook/touche/'\n",
    "input_file = 'topics-task-2-only-titles.xml'\n",
    "list_of_tuples = read_xml(input_dir + input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', 'What is the difference between sex and love?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "getted_request = make_a_search_request('Which is healthiest: coffee, green tea or black tea and why?').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_bodies = [cleanhtml(elem['snippet']) for elem in getted_request['results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['many of our customers are drawn to tea for its potential health benefits, and many want to know which tea will give them the most bang for their buck. &quot;which tea is the healthiest?&quot; is a question we’re often asked.',\n",
       " 'the antioxidant content of a number of popular beverages is compared: black tea, coffee, coke, espresso, grape juice, green tea, hibiscus tea, milk, pepsi, red bull, red tea, red wine, and white wine. which beats out even powdered (matcha) green tea?',\n",
       " 'a: the addition of milk does not appear to affect the bioavailability of the tea flavonoids q: do green and black teas come from different plants? a: no, they both come from the same plant known by its botanical name camellia sinensis. q: does tea contain the same level of caffeine as coffee?',\n",
       " 'both green tea and black tea come from the leaves of the plant camellia sinensis, however the processing that the leaves undergo to make the final tea is different. the leaves for black tea are fully oxidised while those for green teas are lightly steamed before being dried.',\n",
       " 'although india produces mostly black teas, a small amount of green tea (1% of total production) is produced mainly for the afghanistan market. assam is a major growing area covering the brahmaputra valley, stretching from the himalayas down to the bay of bengal.',\n",
       " 'finally, the leaves are &quot;fired,&quot; producing a brownish black tea whose immersion in hot water gives a reddish-brown brew with a stronger flavor than green or oolong teas. oolong tea, which is made from leaves that are partially fermented before being fired, falls midway between green and black teas.',\n",
       " 'finally, the leaves are &quot;fired,&quot; producing a brownish black tea whose immersion in hot water gives a reddish-brown brew with a stronger flavor than green or oolong teas. oolong tea, which is made from leaves that are partially fermented before being fired, falls midway between green and black teas.',\n",
       " 'finally, the leaves are &quot;fired,&quot; producing a brownish black tea whose immersion in hot water gives a reddish-brown brew with a stronger flavor than green or oolong teas. oolong tea, which is made from leaves that are partially fermented before being fired, falls midway between green and black teas.',\n",
       " 'one nutrition “fad” i would like for us to let go of in 2012 is the idea that caffeine (found in coffee, tea, and chocolate) is inherently “bad.” ',\n",
       " 'prior to 1869, sri lanka’s primary export crop was coffee. during that year, a killer blight struck, hemileia vastatrix, which wiped out the island’s vast coffee crop. the dead coffee trees were shipped to england where they were cut up and used for tea-table legs.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthiest\n"
     ]
    }
   ],
   "source": [
    "no_specials_string = re.sub('[!#?,.:\";]', '', 'healthiest:')\n",
    "print(no_specials_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in extractor get params 0\n",
      "words  [['which', 'is', 'healthiest:', 'coffee,', 'green', 'tea', 'or', 'black', 'tea', 'and', 'why?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'B-PREDFULL', 'O', 'O', 'B-OBJ', 'O', 'O', 'B-OBJ', 'O', 'O']]\n",
      "['tea', 'tea']\n",
      "['healthiest:']\n",
      "[]\n",
      "in make scores tea tea ['healthiest:'] []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_scores_3(cleanhtml('Which is healthiest: coffee, green tea or black tea and why?'), answers_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_score(cleanhtml('Sex may or may not include penetration. Differences Between Love and Sex Love Love is a feeling (emotional). There is no exact &quot;right&quot; definition of love for everybody. Love involves feelings of romance and&#x2F;or attraction. Sex: Sex is an event or act'), ('sex', 'love', [], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will be loaded\n",
      "loading\n",
      "extract_objects_predicates gpu 2\n",
      "in extractor get params 0\n",
      "words  [['what', 'is', 'better', 'bread', 'or', 'pizza']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'B-PREDFULL', 'B-OBJ', 'O', 'O']]\n",
      "['bread']\n",
      "['better']\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "tokens  ['What', 'is', 'better', 'bread', 'or', 'pizza']\n",
      "or simple split_sent 4\n",
      "bread pizza\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import models\n",
    "extr = models.extractor()\n",
    "obj1, obj2, pred, asp = extract_objs_asp(extr, \"What is better bread or pizza\")\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext.lower()\n",
    "\n",
    "def count_score(text, nlu_tuple):\n",
    "    (obj1, obj2, pred, asp) = nlu_tuple\n",
    "    r = 1.0\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (len(pred) != 0):\n",
    "            pred = re.sub('[!#?,.:\";]', '', pred[0])\n",
    "            if (obj1 in text and obj2 in text and pred in text):\n",
    "                r += 1.0\n",
    "        if (len(asp) != 0):\n",
    "            asp = re.sub('[!#?,.:\";]', '', asp[0])\n",
    "            if (obj1 in text and obj2 in text and asp in text):\n",
    "                r += 1.0\n",
    "        elif (obj1 in text and obj2 in text):\n",
    "            r = 1.5\n",
    "    else:\n",
    "        if (obj1) in sent or (obj2) in text:\n",
    "            r = 1.1\n",
    "    return r\n",
    "\n",
    "def make_scores_3(query, answers):\n",
    "    (obj1, obj2, pred, asp) = extract_objs_asp(extr, query)\n",
    "    #print (\"in make scores\", obj1, obj2, pred, asp)\n",
    "    scores = [count_score(cleanhtml(answer), (obj1, obj2, pred, asp)) for answer in answers]\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "    # take title from seacrh output from clueweb\n",
    "    # return a cosine similarity between bert embedding of sentences and article title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(output_dir = '/notebook/touche/output/', input_dir = '/notebook/touche/', input_file = 'topics-task-2-only-titles.xml'):\n",
    "    list_of_tuples = read_xml(input_dir + input_file)\n",
    "    common_list = []\n",
    "    \n",
    "    with open(output_dir + 'run_example.txt', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "        \n",
    "    for elem in list_of_tuples[:10]:\n",
    "        qid = elem[0]\n",
    "        Q0 = 'Q0'\n",
    "        query = elem[1]\n",
    "        tag = 'Method3'\n",
    "        response = make_a_search_request(query)\n",
    "        try:\n",
    "            getted_request = response.json()\n",
    "        except:\n",
    "            return getted_request\n",
    "        answers_bodies = [cleanhtml(elem['snippet']) for elem in getted_request['results']]\n",
    "        try:\n",
    "            scores0 = [elem['score'] for elem in getted_request['results']]\n",
    "            docs = [elem['trec_id'] for elem in getted_request['results']]\n",
    "            titles = [elem['title'] for elem in getted_request['results']]\n",
    "            #print (\"query, answers_bodies\", query, answers_bodies)\n",
    "            scores3 = make_scores_3(query, answers_bodies)\n",
    "            scores = [a*b for a,b in zip(scores0, scores3)]\n",
    "            # print (scores0, scores3, scores)\n",
    "        except:\n",
    "            return getted_request\n",
    "        qids = qid*len(scores)\n",
    "        Q0s = [Q0 for elem in scores]\n",
    "        queries = query*len(scores)\n",
    "        tags = [tag for elem in scores]\n",
    "        part_of_commom_list = list(zip(qids, Q0s, docs, scores, tags))\n",
    "        part_of_commom_list = sorted(part_of_commom_list, key = lambda x: x[3], reverse = True) \n",
    "        \n",
    "        qids, Q0s, docs, scores, tags = zip(*part_of_commom_list)\n",
    "        \n",
    "        ranks = range(1, len(scores) + 1)\n",
    "        part_of_commom_list = list(zip(qids, Q0s, docs, ranks, scores, tags))\n",
    "        common_list = common_list + part_of_commom_list\n",
    "        \n",
    "    with open(output_dir + 'run_example3.txt', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7f051c38aa50>]\n",
      "50\n",
      "in extractor get params 0\n",
      "words  [['what', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love?']\n",
      "tokens  ['What', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love', '?']\n",
      "or simple split_sent 6\n",
      "sex love\n",
      "in extractor get params 0\n",
      "words  [['which', 'is', 'better,', 'laptop', 'or', 'desktop?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'B-OBJ', 'O', 'O']]\n",
      "['laptop']\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['which', 'is', 'better,', 'laptop', 'or', 'desktop?']\n",
      "tokens  ['Which', 'is', 'better', ',', 'laptop', 'or', 'desktop', '?']\n",
      "or simple split_sent 5\n",
      "laptop desktop\n",
      "in extractor get params 0\n",
      "words  [['which', 'is', 'better,', 'canon', 'or', 'nikon?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'B-OBJ', 'O', 'O']]\n",
      "['canon']\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['which', 'is', 'better,', 'canon', 'or', 'nikon?']\n",
      "tokens  ['Which', 'is', 'better', ',', 'Canon', 'or', 'Nikon', '?']\n",
      "or index doc snet 5\n",
      "begin end  4 5 Canon\n",
      "obj1 spacy doc sent Canon\n",
      "or index doc snet 5\n",
      "begin end  6 7 Nikon\n",
      "obj2 spacy doc sent Nikon\n",
      "in extractor get params 0\n",
      "words  [['what', 'are', 'the', 'best', 'dish', 'detergents?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'O', 'O']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'are', 'the', 'best', 'dish', 'detergents?']\n",
      "tokens  ['What', 'are', 'the', 'best', 'dish', 'detergents', '?']\n",
      "in extractor get params 0\n",
      "words  [['what', 'are', 'the', 'best', 'cities', 'to', 'live?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'are', 'the', 'best', 'cities', 'to', 'live?']\n",
      "tokens  ['What', 'are', 'the', 'best', 'cities', 'to', 'live', '?']\n",
      "in extractor get params 0\n",
      "words  [['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'u.s.?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O']]\n",
      "['river']\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'u.s.?']\n",
      "tokens  ['What', 'is', 'the', 'longest', 'river', 'in', 'the', 'U.S.', '?']\n",
      "in extractor get params 0\n",
      "words  [['which', 'is', 'healthiest:', 'coffee,', 'green', 'tea', 'or', 'black', 'tea', 'and', 'why?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'B-PREDFULL', 'O', 'O', 'B-OBJ', 'O', 'O', 'B-OBJ', 'O', 'O']]\n",
      "['tea', 'tea']\n",
      "['healthiest:']\n",
      "[]\n",
      "in extractor get params 0\n",
      "words  [['what', 'are', 'advantages', 'and', 'disadvantages', 'of', 'php', 'over', 'python', 'and', 'vice', 'versa?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O']]\n",
      "['python']\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['what', 'are', 'advantages', 'and', 'disadvantages', 'of', 'php', 'over', 'python', 'and', 'vice', 'versa?']\n",
      "tokens  ['What', 'are', 'advantages', 'and', 'disadvantages', 'of', 'PHP', 'over', 'Python', 'and', 'vice', 'versa', '?']\n",
      "in extractor get params 0\n",
      "words  [['why', 'is', 'linux', 'better', 'than', 'windows?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'B-OBJ', 'B-PREDFULL', 'O', 'O']]\n",
      "['linux']\n",
      "['better']\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['why', 'is', 'linux', 'better', 'than', 'windows?']\n",
      "tokens  ['Why', 'is', 'Linux', 'better', 'than', 'Windows', '?']\n",
      "in extractor get params 0\n",
      "words  [['how', 'to', 'sleep', 'better?']]\n",
      "LayerContextWordEmbeddingsBert 2\n",
      "LayerContextWordEmbeddingsBert2 2\n",
      "LayerContextWordEmbeddingsBert3 2\n",
      "LayerContextWordEmbeddingsBert4 2\n",
      "LayerContextWordEmbeddingsBert5 2\n",
      "LayerContextWordEmbeddingsBert6 2\n",
      "LayerContextWordEmbeddingsBert7 2\n",
      "LayerContextWordEmbeddingsBert8 2\n",
      "LayerContextWordEmbeddingsBert9 2\n",
      "extract_objects_predicates tags [['O', 'O', 'O', 'O']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "We try to use spacy\n",
      "split_sent ['how', 'to', 'sleep', 'better?']\n",
      "tokens  ['How', 'to', 'sleep', 'better', '?']\n"
     ]
    }
   ],
   "source": [
    "run_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
