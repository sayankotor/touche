{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  print (\"not\")  \n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/cqas/external_pretrained_models/roberta.hdf5\n",
      "/notebook/cqas/external_pretrained_models/vocab_dir\n",
      "encoder loaded\n",
      "indexer loaded\n",
      "model path  /notebook/cqas/external_pretrained_models/roberta.hdf5\n",
      "model loaded\n",
      "reader loaded\n",
      "loaded extractors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# transformers\n",
    "import pytorch_transformers\n",
    "from pytorch_transformers import *\n",
    "\n",
    "# read file\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "\n",
    "#import rank model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# custom extractor\n",
    "import pickle\n",
    "from my_functions import extractorRoberta\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_extractor = extractorRoberta(my_device = device, model_path = '/notebook/cqas/external_pretrained_models/')\n",
    "print (\"loaded extractors\")\n",
    "\n",
    "from pyterrier import text\n",
    "from pyterrier.text import scorer\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  print (\"not\")  \n",
    "  pt.init()\n",
    "\n",
    "def create_featured_dataset(some_df):\n",
    "    from pyterrier import text\n",
    "    from pyterrier.text import scorer\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='BM25', sort=False)\n",
    "    rtr_bm = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='Tf')\n",
    "    rtr_tf = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='PL2')\n",
    "    rtr_pl2 = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='DFIC')\n",
    "    rtr_dfic = textscorerTf.transform(some_df)\n",
    "    \n",
    "    rtr_pl2_for_merge = rtr_pl2[['qid', 'docno', 'score']]\n",
    "    rtr_pl2_for_merge = rtr_pl2_for_merge.rename(columns={\"score\": \"score_pl2\"})\n",
    "    \n",
    "    rtr_tf_for_merge = rtr_tf[['qid', 'docno', 'score']]\n",
    "    rtr_tf_for_merge = rtr_tf_for_merge.rename(columns={\"score\": \"score_tf\"})\n",
    "    \n",
    "    rtr_bm_for_merge = rtr_bm[['qid', 'docno', 'score']]\n",
    "    rtr_bm_for_merge = rtr_bm_for_merge.rename(columns={\"score\": \"score_bm\"})\n",
    "    \n",
    "    rtr_dfic_for_merge = rtr_dfic[['qid', 'docno', 'score']]\n",
    "    rtr_dfic_for_merge = rtr_dfic_for_merge.rename(columns={\"score\": \"score_dfic\"})\n",
    "    \n",
    "    result = pd.merge(rtr_pl2_for_merge, rtr_tf_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_bm_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_dfic_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, some_df, on=[\"qid\", \"docno\"])\n",
    "    zipped = [result[\"score_pl2\"], result[\"score_tf\"], result[\"score_bm\"], result[\"score_dfic\"], result['baseline_scores'], result[\"is_retrieved\"], result[\"ap_score\"], result[\"objs_score\"]]\n",
    "    unzipped_object = zip(*zipped)\n",
    "    unzipped_list = list(unzipped_object)\n",
    "    list_of_features = [np.array(elem) for elem in unzipped_list]\n",
    "    result['features'] = list_of_features\n",
    "    return result\n",
    "\n",
    "def extract_objs_asp(model_for_extraction, input_string):\n",
    "    model_for_extraction.from_string(input_string)\n",
    "    obj1, obj2, predicates, aspects = model_for_extraction.get_params()\n",
    "    return (obj1.lower(), obj2.lower(), predicates, aspects)\n",
    "\n",
    "\n",
    "def count_score1(text, nlu_tuple):\n",
    "    (obj1, obj2, pred, asp) = nlu_tuple\n",
    "    r = 1.0\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (len(pred) != 0):\n",
    "            pred = re.sub('[!#?,.:\";]', '', pred[0])\n",
    "            if (obj1 in text and obj2 in text and pred in text):\n",
    "                r += 1.0\n",
    "        if (len(asp) != 0):\n",
    "            asp = re.sub('[!#?,.:\";]', '', asp[0])\n",
    "            if (obj1 in text and obj2 in text and asp in text):\n",
    "                r += 1.0\n",
    "        elif (obj1 in text and obj2 in text):\n",
    "            r = 1.5\n",
    "        elif (obj1 in text or obj2 in text):\n",
    "            r = 1.2\n",
    "    else:\n",
    "        if (obj1) in text or (obj2) in text:\n",
    "            r = 1.2\n",
    "    return r\n",
    "\n",
    "def count_score_nlu(nlu_tuple):\n",
    "    if (len(nlu_tuple[0]) == 0):\n",
    "        return 0.0\n",
    "    else: return 1.0\n",
    "\n",
    "\n",
    "def count_score(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (obj1 in text):\n",
    "            r += 1.0\n",
    "        if (obj2 in text):\n",
    "            r += 1.0\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 1.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 1.0\n",
    "    else:\n",
    "        if ((obj1) in text and len(obj1)!= 0) or (obj2 in text and len(obj2) != 0):\n",
    "            r = 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_obj(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and obj1 in text):\n",
    "        r += 1.0\n",
    "    if (len(obj2) != 0 and obj2 in text):\n",
    "        r += 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_asp_pred(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    o1 = (len(obj1) != 0 and obj1 in text)\n",
    "    o2 = (len(obj2) != 0 and obj2 in text)\n",
    "    if (o1 or o2):\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 0.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 0.5\n",
    "    return r\n",
    "\n",
    "\n",
    "def make_scores_obj(query, answers):\n",
    "    print (\"make_scores_obj\")\n",
    "    (obj1, obj2, pred, asp) = extract_objs_asp(extr, query)\n",
    "    print (\"in make scores\", obj1, obj2, pred, asp)\n",
    "    scores_answers = [count_score(cleanhtml(answer), (obj1, obj2, pred, asp)) for answer in answers]\n",
    "    return scores_answers\n",
    "\n",
    "def read_xml(filename):\n",
    "    # convert file filename to list of tuples (number_of_topic, title_of_topic) \n",
    "    # input: filename string\n",
    "    # output: list of corresponding tuples\n",
    "    answer_list = []\n",
    "    xmldoc = minidom.parse(filename)\n",
    "    itemlist = xmldoc.getElementsByTagName('topics')\n",
    "    print(len(itemlist))\n",
    "    print(itemlist)\n",
    "    topic_list = itemlist[0].getElementsByTagName('topic')\n",
    "    print (len(topic_list))\n",
    "    for topic in topic_list:\n",
    "        tuple_for_add = tuple((topic.getElementsByTagName('number')[0].firstChild.nodeValue, topic.getElementsByTagName('title')[0].firstChild.nodeValue))\n",
    "        answer_list.append(tuple_for_add)\n",
    "    return answer_list\n",
    "\n",
    "def make_a_search_request(query):\n",
    "    # return json\n",
    "    # json will be processed further\n",
    "    params = {\n",
    "            \"apikey\": \"0833a307-97d3-462a-99d9-27db400c70da\",\n",
    "            \"query\": query,\n",
    "            \"index\": [\"cw12\"],\n",
    "            \"size\": 10,\n",
    "            \"pretty\": True\n",
    "        }\n",
    "    response = requests.get(url = \"http://www.chatnoir.eu/api/v1/_search\", params = params)\n",
    "    return response\n",
    "\n",
    "def clean_punct(s):\n",
    "    s = re.sub(r'[^\\w\\s]','',s)\n",
    "    return s\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 28 20:11:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 27%   29C    P2    59W / 260W |   3599MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     9W / 260W |   3308MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     5W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    10W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   24C    P8     2W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    15W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    11W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 64%   65C    P2   257W / 260W |   4596MiB / 11019MiB |     80%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade fastrank lightgbm \n",
    "#!pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7fb1f21e7d70>]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from baseline import read_xml\n",
    "topics_2020 = read_xml('topics-task-2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('46', '\\nWhich beverage has more calories per glass: beer or cider?\\n')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_2020[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#r = requests.post('http://10.30.99.211:8261/gpt_small', data = \"What is better for deep learning Python or Matlab?\")\n",
    "#print (r.status_code)\n",
    "import requests\n",
    "from xml.dom import minidom\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read retireved documents and qrels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('/notebook/touche/list_of_un_answ.pkl', 'rb') as f:\n",
    "    answers_2020 = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/touche2021/touche2020-task2-relevance-withbaseline.qrels', 'r') as f:\n",
    "    qrels_lines = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "qrels = [x.strip().split() for x in qrels_lines] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create qrels dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "for elem in qrels:\n",
    "    query, noninf, docno, rank = elem\n",
    "    if (query in qrels_dict.keys()):\n",
    "        qrels_dict[query].append((docno, rank))\n",
    "    else:\n",
    "        qrels_dict[query] = []\n",
    "        qrels_dict[query].append((docno, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clueweb12-1715wb-31-22014', '0'),\n",
       " ('clueweb12-0106wb-15-00715', '0'),\n",
       " ('clueweb12-1313wb-74-02250', '0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_dict['46'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.dataset_readers.dataset_utils import to_bioul\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, Field, MetadataField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "\n",
    "from allennlp.modules.token_embedders import PretrainedTransformerMismatchedEmbedder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.seq2seq_encoders import PassThroughEncoder\n",
    "\n",
    "\n",
    "\n",
    "from allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7fb1f27c0f50>]\n",
      "50\n",
      "1\n",
      "[<DOM Element: topics at 0x7fb0a8138410>]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "topics_2020 = read_xml('topics-task-2.xml')\n",
    "\n",
    "topics_2021 = read_xml('topics-task-2-only-titles-2021.xml')\n",
    "        \n",
    "with open('list_of_un_answ.pcl', 'rb') as f:\n",
    "    answers_2020 = pickle.load(f)\n",
    "            \n",
    "with open('list_of_un_answ_2021.pcl', 'rb') as f:\n",
    "    answers_2021 = pickle.load(f)\n",
    "    \n",
    "with open('touche2020-task2-relevance-withbaseline.qrels', 'r') as f:\n",
    "    qrels_lines = f.readlines()\n",
    "    # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "qrels = [x.strip().split() for x in qrels_lines] \n",
    "\n",
    "qrels_dict = {}\n",
    "for elem in qrels:\n",
    "    query, noninf, docno, rank = elem\n",
    "    if (query in qrels_dict.keys()):\n",
    "        qrels_dict[query].append((docno, rank))\n",
    "    else:\n",
    "        qrels_dict[query] = []\n",
    "        qrels_dict[query].append((docno, rank))\n",
    "            \n",
    "info_df = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"],dtype=object)\n",
    "info_df_train = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"], dtype=object)\n",
    "qrels_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"],dtype=object)\n",
    "qrels_df_train = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"],dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranks1(rtr : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Canonical method for adding a rank column which is calculated based on the score attribute\n",
    "        for each query. Note that the dataframe is NOT sorted by this operation.\n",
    "        Arguments\n",
    "            df: dataframe to create rank attribute for\n",
    "    \"\"\"\n",
    "    rtr.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
    "    if len(rtr) == 0:\n",
    "        rtr[\"rank\"] = pd.Series(index=rtr.index, dtype='int64')\n",
    "        return rtr\n",
    "    print (0)\n",
    "    # -1 assures that first rank will be FIRST_RANK\n",
    "    rtr[\"rank\"] = rtr.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + 1\n",
    "    print (1)\n",
    "    if True:\n",
    "        rtr.sort_values([\"qid\", \"rank\"], ascending=[True,True], inplace=True)\n",
    "    return rtr\n",
    "\n",
    "def transform(model, test_DF):\n",
    "    \"\"\"\n",
    "    Predicts the scores for the given topics.\n",
    "\n",
    "    Args:\n",
    "        topicsTest(DataFrame): A dataframe with the test topics.\n",
    "    \"\"\"\n",
    "    test_DF = test_DF.copy()\n",
    "\n",
    "    # check for change in number of features\n",
    "    found_numf = test_DF.iloc[0].features.shape[0]\n",
    "    if model.num_f is not None:\n",
    "        if found_numf != model.num_f:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (model.num_f, found_numf))\n",
    "    if hasattr(model.learner, 'feature_importances_'):\n",
    "        if len(model.learner.feature_importances_) != found_numf:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (len(model.learner.feature_importances_), found_numf))\n",
    "\n",
    "    test_DF[\"score\"] = model.learner.predict(np.stack(test_DF[\"features\"].values))\n",
    "    return add_ranks1(test_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>score_bm</th>\n",
       "      <th>score_dfic</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>clueweb12-0800wb-21-10162</td>\n",
       "      <td>3.846794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.012786</td>\n",
       "      <td>4.5161</td>\n",
       "      <td>should i learn python or r for data analysis</td>\n",
       "      <td>i am currently a graduate student in predictiv...</td>\n",
       "      <td>1968.1794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.8467939181105413, 6.0, 3.012786302957528, 4...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>clueweb12-0800wb-21-10162</td>\n",
       "      <td>3.846794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.012786</td>\n",
       "      <td>4.5161</td>\n",
       "      <td>should i learn python or r for data analysis</td>\n",
       "      <td>i am currently a graduate student in predictiv...</td>\n",
       "      <td>1968.1794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.8467939181105413, 6.0, 3.012786302957528, 4...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>clueweb12-0800wb-21-10162</td>\n",
       "      <td>3.846794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.012786</td>\n",
       "      <td>4.5161</td>\n",
       "      <td>should i learn python or r for data analysis</td>\n",
       "      <td>i am currently a graduate student in predictiv...</td>\n",
       "      <td>1968.1794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.8467939181105413, 6.0, 3.012786302957528, 4...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>clueweb12-0800wb-21-10162</td>\n",
       "      <td>3.846794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.012786</td>\n",
       "      <td>4.5161</td>\n",
       "      <td>should i learn python or r for data analysis</td>\n",
       "      <td>i am currently a graduate student in predictiv...</td>\n",
       "      <td>1968.1794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.8467939181105413, 6.0, 3.012786302957528, 4...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>clueweb12-0800wb-21-10162</td>\n",
       "      <td>3.846794</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.012786</td>\n",
       "      <td>4.5161</td>\n",
       "      <td>should i learn python or r for data analysis</td>\n",
       "      <td>i am currently a graduate student in predictiv...</td>\n",
       "      <td>1968.1794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3.8467939181105413, 6.0, 3.012786302957528, 4...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                      docno  score_pl2  score_tf  score_bm  score_dfic  \\\n",
       "0  100  clueweb12-0800wb-21-10162   3.846794       6.0  3.012786      4.5161   \n",
       "1  100  clueweb12-0800wb-21-10162   3.846794       6.0  3.012786      4.5161   \n",
       "2  100  clueweb12-0800wb-21-10162   3.846794       6.0  3.012786      4.5161   \n",
       "3  100  clueweb12-0800wb-21-10162   3.846794       6.0  3.012786      4.5161   \n",
       "4  100  clueweb12-0800wb-21-10162   3.846794       6.0  3.012786      4.5161   \n",
       "\n",
       "                                          query  \\\n",
       "0  should i learn python or r for data analysis   \n",
       "1  should i learn python or r for data analysis   \n",
       "2  should i learn python or r for data analysis   \n",
       "3  should i learn python or r for data analysis   \n",
       "4  should i learn python or r for data analysis   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  i am currently a graduate student in predictiv...        1968.1794   \n",
       "1  i am currently a graduate student in predictiv...        1968.1794   \n",
       "2  i am currently a graduate student in predictiv...        1968.1794   \n",
       "3  i am currently a graduate student in predictiv...        1968.1794   \n",
       "4  i am currently a graduate student in predictiv...        1968.1794   \n",
       "\n",
       "   is_retrieved  ap_score  objs_score  \\\n",
       "0           1.0       0.0         2.0   \n",
       "1           1.0       0.0         2.0   \n",
       "2           1.0       0.0         2.0   \n",
       "3           1.0       0.0         2.0   \n",
       "4           1.0       0.0         2.0   \n",
       "\n",
       "                                            features  score  rank  \n",
       "0  [3.8467939181105413, 6.0, 3.012786302957528, 4...    0.7     1  \n",
       "1  [3.8467939181105413, 6.0, 3.012786302957528, 4...    0.7     2  \n",
       "2  [3.8467939181105413, 6.0, 3.012786302957528, 4...    0.7     3  \n",
       "3  [3.8467939181105413, 6.0, 3.012786302957528, 4...    0.7     4  \n",
       "4  [3.8467939181105413, 6.0, 3.012786302957528, 4...    0.7     5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Aspect', 'B-Aspect', 'O', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'at', 'reducing', 'fever', 'in', 'children', 'ibuprofen', 'or', 'aspirin']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   at reducing fever in children ibuprofen or aspirin\n",
      "['ibuprofen', 'aspirin']\n",
      "['better']\n",
      "['reducing', 'fever']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'best', 'rice', 'cookers']\n",
      "['rice']\n",
      "[]\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'buy', 'steel', 'or', 'ceramic', 'knives']\n",
      "['steel', 'ceramic']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['is', 'morning', 'or', 'afternoon', 'sun', 'the', 'best', 'for', 'fruit', 'trees']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'for', 'back', 'pain', 'chiropractic', 'therapy', 'or', 'physical', 'therapy']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   for back pain chiropractic therapy or physical therapy\n",
      "[]\n",
      "['better']\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'O', 'B-Object', 'B-Predicate', 'O', 'O', 'B-Aspect']\n",
      "extract_objects_predicates words ['is', 'kenya', 'or', 'tanzania', 'better', 'for', 'a', 'safari']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 21 {3, 12}\n",
      "string   for a safari\n",
      "['kenya', 'tanzania']\n",
      "['better']\n",
      "['safari']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'B-Predicate', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['how', 'is', 'a', 'masters', 'degree', 'different', 'from', 'a', 'bachelors', 'degree']\n",
      "2\n",
      "ind, word 5 different\n",
      "old start, starts 24 {9}\n",
      "string   from a bachelors degree\n",
      "['masters', 'bachelors']\n",
      "['different']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'family', 'guy', 'or', 'the', 'simpsons']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   family guy or the simpsons\n",
      "['family', 'simpsons']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'I-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'more', 'difficult', 'skiing', 'or', 'snowboarding']\n",
      "2\n",
      "ind, word 2 more\n",
      "old start, starts 9 set()\n",
      "string   difficult skiing or snowboarding\n",
      "['skiing', 'snowboarding']\n",
      "['more']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Object', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['why', 'is', 'basketball', 'better', 'than', 'football']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 18 {7}\n",
      "string   than football\n",
      "['basketball', 'football']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['who', 'is', 'stronger', 'hulk', 'or', 'superman']\n",
      "2\n",
      "ind, word 2 stronger\n",
      "old start, starts 7 set()\n",
      "string   hulk or superman\n",
      "['hulk', 'superman']\n",
      "['stronger']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['B-Object', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'B-Predicate', 'O', 'O', 'O', 'B-Aspect', 'I-Aspect']\n",
      "extract_objects_predicates words ['plastic', 'pots', 'or', 'ceramic', 'pots', 'which', 'is', 'better', 'in', 'terms', 'of', 'plant', 'health']\n",
      "2\n",
      "ind, word 7 better\n",
      "old start, starts 38 {0, 16}\n",
      "string   in terms of plant health\n",
      "['plastic', 'ceramic']\n",
      "['better']\n",
      "['plant', 'health']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'coldest', 'temperature', 'ever', 'recorded', 'on', 'earth', 'and', 'where']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'most', 'popular', 'beer', 'in', 'australia']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['are', 'dogs', 'better', 'than', 'humans']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 {4}\n",
      "string   than humans\n",
      "['dogs', 'humans']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'diet', 'gives', 'the', 'best', 'result', 'to', 'lose', 'weight']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['should', 'i', 'take', 'the', 'ielts', 'or', 'the', 'toefl']\n",
      "['toefl']\n",
      "[]\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Aspect', 'B-Predicate', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['are', 'online', 'courses', 'better', 'than', 'physical', 'classrooms']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 19 {11, 4}\n",
      "string   than physical classrooms\n",
      "['online']\n",
      "['better']\n",
      "['courses']\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'O', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['who', 'was', 'a', 'better', 'boxer', 'muhammad', 'ali', 'or', 'joe', 'frazier']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 10 set()\n",
      "string   boxer muhammad ali or joe frazier\n",
      "['ali']\n",
      "['better']\n",
      "['boxer']\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Aspect', 'B-Predicate', 'B-Object', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'technology', 'performs', 'better', 'apples', 'or', 'googles']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 26 {17}\n",
      "string   apples or googles\n",
      "['apples']\n",
      "['better']\n",
      "['performs']\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['is', 'gold', 'equal', 'to', 'platinum']\n",
      "2\n",
      "ind, word 2 equal\n",
      "old start, starts 8 {3}\n",
      "string   to platinum\n",
      "['gold', 'platinum']\n",
      "['equal']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Aspect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['who', 'is', 'better', 'at', 'learning', 'a', 'foreign', 'language', 'kids', 'or', 'adults']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 7 set()\n",
      "string   at learning a foreign language kids or adults\n",
      "[]\n",
      "['better']\n",
      "['learning']\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 's', 'the', 'difference', 'between', 'coffee', 'espresso', 'cappuccino', 'and', 'latte']\n",
      "['latte']\n",
      "[]\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'city', 'is', 'better', 'london', 'or', 'paris']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 14 set()\n",
      "string   london or paris\n",
      "['london', 'paris']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'a', 'conditioner', 'or', 'a', 'moisturizer']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   a conditioner or a moisturizer\n",
      "['conditioner', 'moisturizer']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Aspect', 'B-Predicate', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['are', 'artificial', 'sweeteners', 'better', 'than', 'white', 'sugar']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 26 {4, 15}\n",
      "string   than white sugar\n",
      "['artificial', 'sugar']\n",
      "['better']\n",
      "['sweeteners']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['is', 'it', 'healthier', 'to', 'bake', 'than', 'to', 'fry', 'food']\n",
      "2\n",
      "ind, word 2 healthier\n",
      "old start, starts 6 set()\n",
      "string   to bake than to fry food\n",
      "['bake', 'fry']\n",
      "['healthier']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'algorithm', 'is', 'better', 'quicksort', 'or', 'merge', 'sort']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 19 set()\n",
      "string   quicksort or merge sort\n",
      "['quicksort']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'more', 'interesting', 'computer', 'science', 'or', 'computer', 'engineering']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'difference', 'between', 'a', 'vegan', 'and', 'a', 'vegetarian']\n",
      "['vegan', 'vegetarian']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Object', 'B-Aspect', 'B-Predicate', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['does', 'unpasteurized', 'cheese', 'taste', 'better', 'than', 'pasteurized', 'cheese']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 32 {26, 19}\n",
      "string   than pasteurized cheese\n",
      "1\n",
      "ind, word 7 cheese\n",
      "old start, starts 19 {32, 26, 19}\n",
      "string   taste better than pasteurized cheese\n",
      "new start 56\n",
      "['cheese', 'cheese']\n",
      "['better']\n",
      "['taste']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Predicate', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'light', 'bulb', 'is', 'better', 'incandescent', 'or', 'fluorescent']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 20 set()\n",
      "string   incandescent or fluorescent\n",
      "['fluorescent']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object', 'I-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'difference', 'between', 'quantum', 'physics', 'and', 'quantum', 'mechanics']\n",
      "1\n",
      "ind, word 8 quantum\n",
      "old start, starts 31 {31}\n",
      "string   physics and quantum mechanics\n",
      "new start 51\n",
      "['quantum', 'quantum']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'B-Object', 'O', 'B-Object', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'cow', 'milk', 'or', 'goat', 'milk']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   cow milk or goat milk\n",
      "1\n",
      "ind, word 7 milk\n",
      "old start, starts 19 {8, 27, 19, 15}\n",
      "string   or goat milk\n",
      "new start 32\n",
      "['cow', 'milk', 'goat', 'milk']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 4\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['B-Object', 'O', 'B-Object', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['psoriasis', 'vs', 'eczema', 'what', 'is', 'the', 'difference']\n",
      "['psoriasis', 'eczema']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['i', 'am', 'planning', 'to', 'buy', 'sneakers', 'which', 'are', 'better', 'adidas', 'or', 'nike']\n",
      "2\n",
      "ind, word 8 better\n",
      "old start, starts 40 set()\n",
      "string   adidas or nike\n",
      "['adidas', 'nike']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'O', 'O', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['is', 'obamacare', 'really', 'any', 'better', 'than', 'medicare']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 24 {3}\n",
      "string   than medicare\n",
      "['obamacare', 'medicare']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'major', 'in', 'philosophy', 'or', 'psychology']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'differences', 'between', 'biodegradable', 'and', 'nonbiodegradable', 'wastes']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'good', 'business', 'books', 'to', 'read']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Aspect', 'B-Predicate', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['when', 'are', 'random', 'forest', 'classifiers', 'better', 'than', 'decision', 'trees']\n",
      "2\n",
      "ind, word 5 better\n",
      "old start, starts 35 {23}\n",
      "string   than decision trees\n",
      "[]\n",
      "['better']\n",
      "['classifiers']\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'wood', 'vs', 'stone', 'mulch']\n",
      "['wood', 'stone']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Aspect', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['is', 'rain', 'water', 'better', 'than', 'tap', 'water', 'for', 'plants']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 14 {8, 3}\n",
      "string   than tap water for plants\n",
      "['rain', 'tap']\n",
      "['better']\n",
      "['water']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['suitcases', 'hard', 'or', 'soft']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'I-Predicate', 'I-Predicate', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'more', 'environmentally', 'friendly', 'a', 'hybrid', 'or', 'a', 'diesel']\n",
      "2\n",
      "ind, word 2 more\n",
      "old start, starts 9 set()\n",
      "string   environmentally friendly a hybrid or a diesel\n",
      "['hybrid', 'diesel']\n",
      "['more']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'healthier', 'to', 'wear', 'boxers', 'or', 'briefs']\n",
      "2\n",
      "ind, word 2 healthier\n",
      "old start, starts 9 set()\n",
      "string   to wear boxers or briefs\n",
      "['boxers', 'briefs']\n",
      "['healthier']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'difference', 'between', 'a', 'blender', 'vs', 'a', 'food', 'processor']\n",
      "['blender', 'processor']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'rock', 'or', 'rap']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   rock or rap\n",
      "['rock', 'rap']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['do', 'you', 'think', 'imagination', 'is', 'better', 'than', 'knowledge']\n",
      "2\n",
      "ind, word 5 better\n",
      "old start, starts 28 {13}\n",
      "string   than knowledge\n",
      "['imagination', 'knowledge']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'learn', 'python', 'or', 'r', 'for', 'data', 'analysis']\n",
      "['python', 'r']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'difference', 'between', 'sex', 'and', 'love']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'a', 'laptop', 'or', 'a', 'desktop']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   a laptop or a desktop\n",
      "['laptop', 'desktop']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'canon', 'or', 'nikon']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   canon or nikon\n",
      "['canon', 'nikon']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'best', 'dish', 'detergents']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'best', 'cities', 'to', 'live', 'in']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'us']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'is', 'healthiest', 'coffee', 'green', 'tea', 'or', 'black', 'tea', 'and', 'why']\n",
      "1\n",
      "ind, word 8 tea\n",
      "old start, starts 33 {33}\n",
      "string   or black tea and why\n",
      "new start 46\n",
      "['tea', 'tea']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Aspect', 'O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'advantages', 'and', 'disadvantages', 'of', 'php', 'over', 'python', 'and', 'vice', 'versa']\n",
      "['php', 'python']\n",
      "[]\n",
      "['advantages']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Object', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['why', 'is', 'linux', 'better', 'than', 'windows']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 13 {7}\n",
      "string   than windows\n",
      "['linux', 'windows']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Aspect', 'B-Predicate']\n",
      "extract_objects_predicates words ['how', 'to', 'sleep', 'better']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 13 {7}\n",
      "string  \n",
      "[]\n",
      "['better']\n",
      "['sleep']\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'buy', 'an', 'lcd', 'tv', 'or', 'a', 'plasma', 'tv']\n",
      "['lcd', 'plasma']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['B-Object', 'O', 'B-Object', 'O', 'O', 'O', 'B-Predicate', 'O']\n",
      "extract_objects_predicates words ['train', 'or', 'plane', 'which', 'is', 'the', 'better', 'choice']\n",
      "2\n",
      "ind, word 6 better\n",
      "old start, starts 28 {0, 9}\n",
      "string   choice\n",
      "['train', 'plane']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'highest', 'mountain', 'on', 'earth']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['should', 'one', 'prefer', 'chinese', 'medicine', 'or', 'western', 'medicine']\n",
      "['chinese']\n",
      "[]\n",
      "[]\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'best', 'washing', 'machine', 'brands']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'buy', 'or', 'rent']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O', 'O']\n",
      "extract_objects_predicates words ['do', 'you', 'prefer', 'cats', 'or', 'dogs', 'and', 'why']\n",
      "['cats', 'dogs']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O', 'B-Aspect', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'the', 'better', 'way', 'to', 'grill', 'outdoors', 'gas', 'or', 'charcoal']\n",
      "['gas', 'charcoal']\n",
      "[]\n",
      "['grill']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'mac', 'or', 'pc']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   mac or pc\n",
      "['mac', 'pc']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'to', 'use', 'a', 'brush', 'or', 'a', 'sponge']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   to use a brush or a sponge\n",
      "['brush', 'sponge']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'linux', 'or', 'microsoft']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   linux or microsoft \n",
      "['linux', 'microsoft']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'pepsi', 'or', 'coke']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   pepsi or coke \n",
      "['pepsi', 'coke']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'B-Aspect', 'O', 'B-Object', 'B-Aspect']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'google', 'search', 'or', 'yahoo', 'search']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   google search or yahoo search \n",
      "['google', 'yahoo']\n",
      "['better']\n",
      "['search', 'search']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'one', 'is', 'better', 'netflix', 'or', 'blockbuster']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 13 set()\n",
      "string   netflix or blockbuster\n",
      "['netflix', 'blockbuster']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Object', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'browser', 'is', 'better', 'internet', 'explorer', 'or', 'firefox']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 17 set()\n",
      "string   internet explorer or firefox\n",
      "['internet', 'explorer', 'firefox']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 3\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'a', 'better', 'vehicle', 'bmw', 'or', 'audi']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 11 set()\n",
      "string   vehicle bmw or audi\n",
      "['bmw', 'audi']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'O', 'B-Object', 'B-Aspect', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['which', 'one', 'is', 'better', 'an', 'electric', 'stove', 'or', 'a', 'gas', 'stove']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 13 set()\n",
      "string   an electric stove or a gas stove\n",
      "['electric', 'gas']\n",
      "['better']\n",
      "['stove']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'planes', 'are', 'best', 'boeing', 'or', 'airbus']\n",
      "['boeing', 'airbus']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object', 'I-Object']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'disneyland', 'or', 'disney', 'world']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   disneyland or disney world \n",
      "1\n",
      "ind, word 5 disney\n",
      "old start, starts 16 {16, 9}\n",
      "string  land or disney world \n",
      "new start 30\n",
      "['disneyland', 'disney']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['should', 'i', 'buy', 'an', 'xbox', 'or', 'a', 'playstation']\n",
      "['xbox', 'playstation']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'has', 'more', 'caffeine', 'coffee', 'or', 'tea']\n",
      "2\n",
      "ind, word 2 more\n",
      "old start, starts 10 set()\n",
      "string   caffeine coffee or tea\n",
      "['coffee', 'tea']\n",
      "['more']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object', 'O', 'O']\n",
      "extract_objects_predicates words ['which', 'is', 'better', 'led', 'or', 'lcd', 'reception', 'displays']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 9 set()\n",
      "string   led or lcd reception displays\n",
      "['led', 'lcd']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'asp', 'or', 'php']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   asp or php\n",
      "['asp', 'php']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'O', 'O', 'B-Aspect', 'O', 'O', 'O', 'O', 'O', 'B-Object', 'B-Aspect']\n",
      "extract_objects_predicates words ['what', 'is', 'better', 'for', 'the', 'environment', 'a', 'real', 'or', 'a', 'fake', 'christmas', 'tree']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 8 set()\n",
      "string   for the environment a real or a fake christmas tree\n",
      "['christmas']\n",
      "['better']\n",
      "['environment', 'tree']\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['do', 'you', 'prefer', 'tampons', 'or', 'pads']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "len(objects) 0\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'O', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['what', 'ide', 'is', 'better', 'for', 'java', 'netbeans', 'or', 'eclipse']\n",
      "2\n",
      "ind, word 3 better\n",
      "old start, starts 12 {5}\n",
      "string   for java netbeans or eclipse\n",
      "['ide', 'java', 'eclipse']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 3\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Predicate', 'O', 'B-Object', 'O', 'O', 'O', 'B-Aspect', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['is', 'opengl', 'better', 'than', 'direct3d', 'in', 'terms', 'of', 'portability', 'to', 'different', 'platforms']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts 10 {3}\n",
      "string   than direct3d in terms of portability to different platforms\n",
      "['opengl', 'direct3d']\n",
      "['better']\n",
      "['portability']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'B-Object', 'O', 'B-Object', 'O', 'O']\n",
      "extract_objects_predicates words ['what', 'are', 'the', 'differences', 'between', 'mysql', 'and', 'postgresql', 'in', 'performance']\n",
      "['mysql', 'postgresql']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'O', 'B-Predicate', 'I-Predicate', 'O', 'O', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['is', 'java', 'code', 'more', 'readable', 'than', 'code', 'written', 'in', 'scala']\n",
      "2\n",
      "ind, word 3 more\n",
      "old start, starts 13 {3}\n",
      "string   readable than code written in scala\n",
      "['java', 'scala']\n",
      "['more']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'B-Object', 'O', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['which', 'operating', 'system', 'has', 'better', 'performance', 'windows', '7', 'or', 'windows', '8']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 27 set()\n",
      "string   performance windows 7 or windows 8\n",
      "1\n",
      "ind, word 9 windows\n",
      "old start, starts 46 {34, 27, 46}\n",
      "string   7 or windows 8\n",
      "new start 59\n",
      "['windows', 'windows']\n",
      "['better']\n",
      "['performance']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'I-Aspect', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'smartphone', 'has', 'a', 'better', 'battery', 'life', 'xperia', 'or', 'iphone']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 23 set()\n",
      "string   battery life xperia or iphone\n",
      "['iphone']\n",
      "['better']\n",
      "['battery', 'life']\n",
      "len(objects) 1\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'four', 'wheel', 'truck', 'is', 'better', 'ford', 'or', 'toyota']\n",
      "2\n",
      "ind, word 5 better\n",
      "old start, starts 26 set()\n",
      "string   ford or toyota\n",
      "['ford', 'toyota']\n",
      "['better']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Object', 'O', 'O', 'B-Object', 'O', 'O', 'O']\n",
      "extract_objects_predicates words ['should', 'i', 'prefer', 'a', 'leica', 'camera', 'over', 'nikon', 'for', 'portrait', 'photographs']\n",
      "['leica', 'nikon']\n",
      "[]\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'company', 'has', 'a', 'larger', 'capitalization', 'apple', 'or', 'microsoft']\n",
      "2\n",
      "ind, word 4 larger\n",
      "old start, starts 20 set()\n",
      "string   capitalization apple or microsoft\n",
      "['apple', 'microsoft']\n",
      "['larger']\n",
      "['capitalization']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'laptop', 'has', 'a', 'better', 'durability', 'hp', 'or', 'dell']\n",
      "2\n",
      "ind, word 4 better\n",
      "old start, starts 19 set()\n",
      "string   durability hp or dell\n",
      "['hp', 'dell']\n",
      "['better']\n",
      "['durability']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'B-Aspect', 'O', 'O', 'B-Object', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'beverage', 'has', 'more', 'calories', 'per', 'glass', 'beer', 'or', 'cider']\n",
      "2\n",
      "ind, word 3 more\n",
      "old start, starts 19 set()\n",
      "string   calories per glass beer or cider\n",
      "['beer', 'cider']\n",
      "['more']\n",
      "['calories']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Aspect', 'I-Aspect', 'O', 'B-Object', 'B-Predicate', 'O', 'O', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['is', 'admission', 'rate', 'in', 'stanford', 'higher', 'than', 'that', 'of', 'mit']\n",
      "2\n",
      "ind, word 5 higher\n",
      "old start, starts 30 {21, 3, 13}\n",
      "string   than that of mit\n",
      "['stanford', 'mit']\n",
      "['higher']\n",
      "['admission', 'rate']\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Object', 'B-Predicate', 'O', 'B-Object']\n",
      "extract_objects_predicates words ['is', 'pasta', 'healthier', 'than', 'pizza']\n",
      "2\n",
      "ind, word 2 healthier\n",
      "old start, starts 9 {3}\n",
      "string   than pizza\n",
      "['pasta', 'pizza']\n",
      "['healthier']\n",
      "[]\n",
      "len(objects) 2\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'O', 'O', 'B-Predicate', 'I-Predicate', 'O', 'B-Aspect', 'O', 'B-Object', 'I-Object', 'O', 'B-Object', 'B-Object']\n",
      "extract_objects_predicates words ['which', 'city', 'is', 'more', 'expensive', 'to', 'live', 'in', 'san', 'francisco', 'or', 'new', 'york']\n",
      "2\n",
      "ind, word 3 more\n",
      "old start, starts 14 set()\n",
      "string   expensive to live in san francisco or new york\n",
      "['san', 'new', 'york']\n",
      "['more']\n",
      "['live']\n",
      "len(objects) 3\n",
      "in extractor get params 0\n",
      "self prredicates  \n",
      "extract_objects_predicates tags ['O', 'B-Aspect', 'O', 'B-Predicate', 'B-Object', 'O', 'B-Object', 'O']\n",
      "extract_objects_predicates words ['whose', 'salary', 'is', 'higher', 'basketball', 'or', 'soccer', 'players']\n",
      "2\n",
      "ind, word 3 higher\n",
      "old start, starts 16 {6}\n",
      "string   basketball or soccer players\n",
      "['basketball', 'soccer']\n",
      "['higher']\n",
      "['salary']\n",
      "len(objects) 2\n",
      "info_df head (2021)  100    qid                                         query  \\\n",
      "0  100  should i learn python or r for data analysis   \n",
      "1  100  should i learn python or r for data analysis   \n",
      "2  100  should i learn python or r for data analysis   \n",
      "3  100  should i learn python or r for data analysis   \n",
      "4  100  should i learn python or r for data analysis   \n",
      "\n",
      "                       docno  \\\n",
      "0  clueweb12-0800wb-21-10162   \n",
      "1  clueweb12-1000tw-36-03099   \n",
      "2  clueweb12-1100tw-49-05402   \n",
      "3  clueweb12-0900tw-50-10644   \n",
      "4  clueweb12-1314wb-49-25640   \n",
      "\n",
      "                                                text  baseline_scores  \\\n",
      "0  i am currently a graduate student in predictiv...        1968.1794   \n",
      "1  one possibility that is often put forward is t...        1846.1644   \n",
      "2  why i started learning data science and picked...        1652.3538   \n",
      "3  to r-bloggers) we&#x27;re starting to see a de...        1409.8422   \n",
      "4  you can subscribe for e-mail updates: and get ...        1012.6029   \n",
      "\n",
      "   is_retrieved  ap_score  objs_score  \n",
      "0           1.0       0.0         2.0  \n",
      "1           1.0       0.0         2.0  \n",
      "2           1.0       0.0         1.0  \n",
      "3           1.0       0.0         1.0  \n",
      "4           1.0       0.0         1.0  \n",
      "info_df_test head (2020)  4922   qid                                        query                      docno  \\\n",
      "0   1  what is the difference between sex and love  clueweb12-1214wb-88-29751   \n",
      "1   1  what is the difference between sex and love  clueweb12-1811wb-62-08418   \n",
      "2   1  what is the difference between sex and love  clueweb12-0200wb-79-18105   \n",
      "3   1  what is the difference between sex and love  clueweb12-1311wb-38-04762   \n",
      "4   1  what is the difference between sex and love  clueweb12-0200tw-85-01106   \n",
      "\n",
      "                                                text  baseline_scores  \\\n",
      "0  sex may or may not include penetration. differ...        2406.7341   \n",
      "1  having sex and a rape are two completely d...        2396.6697   \n",
      "2  home &gt; articles &gt; sex, sexuality &amp; p...        2270.9827   \n",
      "3  home &gt;&gt;&gt; sex education 2.0 &gt;&gt;&g...        2096.9185   \n",
      "4  things have changed so much and it has been ye...        2010.6464   \n",
      "\n",
      "   is_retrieved  ap_score  objs_score  \n",
      "0           0.0       0.0         0.0  \n",
      "1           0.0       0.0         0.0  \n",
      "2           0.0       0.0         0.0  \n",
      "3           0.0       0.0         0.0  \n",
      "4           0.0       0.0         0.0  \n",
      "qrels_df_train  1783   qid                      docno label\n",
      "0   1  clueweb12-0001wb-05-12311     0\n",
      "1   1  clueweb12-1811wb-62-08424     1\n",
      "2   1  clueweb12-1811wb-62-08423     1\n",
      "3   1  clueweb12-1217wb-47-14048     0\n",
      "4   1  clueweb12-1811wb-62-08425     1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for elem in topics_2021:\n",
    "    qid, query = elem[0], elem[1].strip('\\n')\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query = cleanhtml(query)\n",
    "    my_extractor.from_string(query)\n",
    "    structures = my_extractor.get_params()\n",
    "        \n",
    "for ind, answer in enumerate(answers_2021[qid]):\n",
    "    docno = answer[1]\n",
    "    score = answer[0]\n",
    "    text = answer[3]\n",
    "\n",
    "            #nlu_score = count_score(text, structures)\n",
    "    objs_score = count_score_obj(text, structures)\n",
    "    ap_score = count_score_asp_pred(text, structures)\n",
    "    is_retrieved = count_score_nlu(structures)\n",
    "    df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"text\":text, \"baseline_scores\":score, \"is_retrieved\":is_retrieved, \"ap_score\":ap_score, \"objs_score\":objs_score}\n",
    "    info_df = info_df.append(df_row, ignore_index= True)\n",
    "            \n",
    "    #create train df and crels\n",
    "    \n",
    "for elem in topics_2020:\n",
    "    qid, query = elem[0], elem[1].strip('\\n')\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query = cleanhtml(query)\n",
    "    my_extractor.from_string(query)\n",
    "    structures = my_extractor.get_params()\n",
    "\n",
    "    for ind, answer in enumerate(answers_2020[qid]):\n",
    "        docno = answer[1]\n",
    "        score = answer[0]\n",
    "        text = answer[3]\n",
    "\n",
    "        nlu_score = count_score(text, structures)\n",
    "        objs_score = count_score_obj(text, structures)\n",
    "        ap_score = count_score_asp_pred(text, structures)\n",
    "        is_retrieved = count_score_nlu(structures)\n",
    "        df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"text\":text, \"baseline_scores\":score, \"is_retrieved\":is_retrieved, \"ap_score\":ap_score, \"objs_score\":objs_score}\n",
    "        info_df_train = info_df_train.append(df_row, ignore_index= True)\n",
    "                \n",
    "    for qrel in qrels_dict[qid]:\n",
    "        docno, label = qrel\n",
    "        df_row = {\"qid\":qid, \"docno\":docno, \"label\":label}\n",
    "        qrels_df_train = qrels_df_train.append(df_row, ignore_index= True)\n",
    "       \n",
    "    \n",
    "print (\"info_df head (2021) \", len(info_df), info_df.head())\n",
    "print (\"info_df_test head (2020) \", len(info_df_train), info_df_train.head())\n",
    "print (\"qrels_df_train \", len(qrels_df_train), qrels_df_train.head())\n",
    "    \n",
    "    \n",
    "test_ds = create_featured_dataset(info_df)\n",
    "result = create_featured_dataset(info_df_train)\n",
    "    \n",
    "rf = RandomForestRegressor(n_estimators=20)\n",
    "rf_pipe = pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(result, qrels_df_train)\n",
    "answs = transform(rf_pipe, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0001wb-05-12311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1217wb-47-14048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344</th>\n",
       "      <td>50</td>\n",
       "      <td>clueweb12-1200tw-39-15054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>50</td>\n",
       "      <td>clueweb12-1019wb-89-15610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>50</td>\n",
       "      <td>clueweb12-1000tw-07-02287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>50</td>\n",
       "      <td>clueweb12-1300tw-70-00891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>50</td>\n",
       "      <td>clueweb12-0206wb-00-16297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5349 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                      docno label\n",
       "0      1  clueweb12-0001wb-05-12311     0\n",
       "1      1  clueweb12-1811wb-62-08424     1\n",
       "2      1  clueweb12-1811wb-62-08423     1\n",
       "3      1  clueweb12-1217wb-47-14048     0\n",
       "4      1  clueweb12-1811wb-62-08425     1\n",
       "...   ..                        ...   ...\n",
       "5344  50  clueweb12-1200tw-39-15054     0\n",
       "5345  50  clueweb12-1019wb-89-15610     0\n",
       "5346  50  clueweb12-1000tw-07-02287     0\n",
       "5347  50  clueweb12-1300tw-70-00891     0\n",
       "5348  50  clueweb12-0206wb-00-16297     0\n",
       "\n",
       "[5349 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CUDA_VISIBLE_DEVICES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d3dd480d83d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCUDA_VISIBLE_DEVICES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CUDA_VISIBLE_DEVICES' is not defined"
     ]
    }
   ],
   "source": [
    "CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder loaded\n",
      "indexer loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from allennlp import models\n",
    "from allennlp.models import SimpleTagger\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab= Vocabulary.from_files(\"/notebook/cqas/external_pretrained_models/vocab_dir\")\n",
    "BERT_MODEL = 'google/electra-base-discriminator'\n",
    "embedder = PretrainedTransformerMismatchedEmbedder(model_name=BERT_MODEL)\n",
    "text_field_embedder = BasicTextFieldEmbedder({'tokens': embedder})\n",
    "seq2seq_encoder = PassThroughEncoder(input_dim=embedder.get_output_dim())\n",
    "print (\"encoder loaded\")\n",
    "indexer = PretrainedTransformerMismatchedIndexer(model_name=BERT_MODEL)\n",
    "print (\"indexer loaded\")\n",
    "model = SimpleTagger(text_field_embedder=text_field_embedder, \n",
    "                      vocab=vocab, \n",
    "                      encoder=seq2seq_encoder,\n",
    "                      calculate_span_f1=True,\n",
    "                    label_encoding='IOB1')\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"/notebook/cqas/external_pretrained_models/roberta.hdf5\", map_location='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6d10510fbf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/notebook/cqas/external_pretrained_models/bertttt.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "a = torch.load(\"/notebook/cqas/external_pretrained_models/bertttt.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5e17cb0edb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdicrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/notebook/NLU_last_version/roberta.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "dicrt = torch.load(\"/notebook/NLU_last_version/roberta.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for strucutres retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 26 16:50:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 35%   48C    P2    63W / 260W |   3830MiB / 11019MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 41%   49C    P2    72W / 260W |   3135MiB / 11019MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 78%   74C    P2   204W / 260W |  11013MiB / 11019MiB |     79%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 83%   77C    P2   217W / 260W |  10498MiB / 11019MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 67%   66C    P2   192W / 260W |   6690MiB / 11019MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 83%   78C    P2   202W / 260W |   4596MiB / 11019MiB |     71%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 77%   72C    P2   254W / 260W |  10946MiB / 11019MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8    15W / 260W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objs_asp(model_for_extraction, input_string):\n",
    "    model_for_extraction.from_string(input_string)\n",
    "    obj1, obj2, predicates, aspects = model_for_extraction.get_params()\n",
    "    return (obj1.lower(), obj2.lower(), predicates, aspects)\n",
    "\n",
    "\n",
    "def count_score1(text, nlu_tuple):\n",
    "    (obj1, obj2, pred, asp) = nlu_tuple\n",
    "    r = 1.0\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (len(pred) != 0):\n",
    "            pred = re.sub('[!#?,.:\";]', '', pred[0])\n",
    "            if (obj1 in text and obj2 in text and pred in text):\n",
    "                r += 1.0\n",
    "        if (len(asp) != 0):\n",
    "            asp = re.sub('[!#?,.:\";]', '', asp[0])\n",
    "            if (obj1 in text and obj2 in text and asp in text):\n",
    "                r += 1.0\n",
    "        elif (obj1 in text and obj2 in text):\n",
    "            r = 1.5\n",
    "        elif (obj1 in text or obj2 in text):\n",
    "            r = 1.2\n",
    "    else:\n",
    "        if (obj1) in text or (obj2) in text:\n",
    "            r = 1.2\n",
    "    return r\n",
    "\n",
    "def make_scores_obj(query, answers):\n",
    "    print (\"make_scores_obj\")\n",
    "    (obj1, obj2, pred, asp) = extract_objs_asp(extr, query)\n",
    "    print (\"in make scores\", obj1, obj2, pred, asp)\n",
    "    scores_answers = [count_score(cleanhtml(answer), (obj1, obj2, pred, asp)) for answer in answers]\n",
    "    return scores_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create proper pandas df documents and qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from help_response import create_list_of_unigue_answers, cleanhtml, clean_punct, read_xml\n",
    "\n",
    "info_df = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"])\n",
    "info_df_test = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"])\n",
    "qrels_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"])\n",
    "qrels_df_test = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"])\n",
    "\n",
    "for elem in topics_2020:\n",
    "    qid, query = elem[0], elem[1].strip('\\n')\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    query = cleanhtml(query)\n",
    "    my_extractor.from_string(query)\n",
    "    structures = my_extractor.get_params()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ind, answer in enumerate(answers_2020[qid]):\n",
    "        docno = answer[1]\n",
    "        score = answer[0]\n",
    "        text = answer[3]\n",
    "        \n",
    "        nlu_score = count_score(text, structures)\n",
    "        objs_score = count_score_obj(text, structures)\n",
    "        ap_score = count_score_asp_pred(text, structures)\n",
    "        is_retrieved = count_score_nlu(structures)\n",
    "        df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"text\":text, \"baseline_scores\":score, \"is_retrieved\":is_retrieved, \"ap_score\":ap_score, \"objs_score\":objs_score}\n",
    "        if (int(qid) < 40):\n",
    "            info_df = info_df.append(df_row, ignore_index= True)\n",
    "        else:\n",
    "            info_df_test = info_df_test.append(df_row, ignore_index= True)\n",
    "            \n",
    "    for qrel in qrels_dict[qid]:\n",
    "        docno, label = qrel\n",
    "        df_row = {\"qid\":qid, \"docno\":docno, \"label\":label}\n",
    "        if (int(qid) < 40):\n",
    "            qrels_df = qrels_df.append(df_row, ignore_index= True)\n",
    "        else:\n",
    "            qrels_df_test = qrels_df_test.append(df_row, ignore_index= True)\n",
    "            \n",
    "\n",
    "\n",
    "#textscorerTf = pt.text.scorer(body_attr=\"text\", wmodel=\"Tf\")\n",
    "#rtr = textscorerTf.transform("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2406.7341,\n",
       "  'clueweb12-1214wb-88-29751',\n",
       "  'difference between love and sex - student.com articles',\n",
       "  'sex may or may not include penetration. differences between love and sex love love is a feeling (emotional). there is no exact &quot;right&quot; definition of love for everybody. love involves feelings of romance and&#x2f;or attraction. sex: sex is an event or act'),\n",
       " (2396.6697,\n",
       "  'clueweb12-1811wb-62-08418',\n",
       "  'the difference between rape, sex and love',\n",
       "  'having sex and a rape are two completely different ideas. while the former is enjoying the feeling between two individual species, the later is aggression of the will power of one over another.'),\n",
       " (2270.9827,\n",
       "  'clueweb12-0200wb-79-18105',\n",
       "  'helpingteens.org: the differences between love &amp; sex. | sex, sexuality',\n",
       "  'home &gt; articles &gt; sex, sexuality &amp; pregnancy &gt; the differences between love &amp; sex. love and sex are not the same thing. love is an emotion or a feeling. there is no one definition of love because the word &quot;love&quot; can mean many different things to many different people.')]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_2020['1'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from help_response import create_list_of_unigue_answers, cleanhtml, clean_punct, read_xml\n",
    "text = \"sex may or may not include penetration. differences between love and sex love love is a feeling (emotional). there is no exact &quot;right&quot; definition of love for everybody. love involves feelings of romance and&#x2f;or attraction. sex: sex is an event or act'\"\n",
    "text = cleanhtml(text)\n",
    "structures = ('', '', [], [])\n",
    "count_score(text, structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>nlu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>sex may or may not include penetration. differ...</td>\n",
       "      <td>2406.7341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1811wb-62-08418</td>\n",
       "      <td>having sex and a rape are two completely d...</td>\n",
       "      <td>2396.6697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>home &amp;gt; articles &amp;gt; sex, sexuality &amp;amp; p...</td>\n",
       "      <td>2270.9827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1311wb-38-04762</td>\n",
       "      <td>home &amp;gt;&amp;gt;&amp;gt; sex education 2.0 &amp;gt;&amp;gt;&amp;g...</td>\n",
       "      <td>2096.9185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200tw-85-01106</td>\n",
       "      <td>things have changed so much and it has been ye...</td>\n",
       "      <td>2010.6464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                        query                      docno  \\\n",
       "0   1  what is the difference between sex and love  clueweb12-1214wb-88-29751   \n",
       "1   1  what is the difference between sex and love  clueweb12-1811wb-62-08418   \n",
       "2   1  what is the difference between sex and love  clueweb12-0200wb-79-18105   \n",
       "3   1  what is the difference between sex and love  clueweb12-1311wb-38-04762   \n",
       "4   1  what is the difference between sex and love  clueweb12-0200tw-85-01106   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  sex may or may not include penetration. differ...        2406.7341   \n",
       "1  having sex and a rape are two completely d...        2396.6697   \n",
       "2  home &gt; articles &gt; sex, sexuality &amp; p...        2270.9827   \n",
       "3  home &gt;&gt;&gt; sex education 2.0 &gt;&gt;&g...        2096.9185   \n",
       "4  things have changed so much and it has been ye...        2010.6464   \n",
       "\n",
       "   is_retrieved  nlu_score  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve comaparative sructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objs_asp(model_for_extraction, input_string):\n",
    "    model_for_extraction.from_string(input_string)\n",
    "    obj1, obj2, predicates, aspects = model_for_extraction.get_params()\n",
    "    model_for_extraction.clear_params()\n",
    "    return (obj1.lower(), obj2.lower(), predicates, aspects)\n",
    "\n",
    "def count_score_nlu(nlu_tuple):\n",
    "    if (len(nlu_tuple[0]) == 0):\n",
    "        return 0.0\n",
    "    else: return 1.0\n",
    "\n",
    "\n",
    "def count_score(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (obj1 in text):\n",
    "            r += 1.0\n",
    "        if (obj2 in text):\n",
    "            r += 1.0\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 1.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 1.0\n",
    "    else:\n",
    "        if ((obj1) in text and len(obj1)!= 0) or (obj2 in text and len(obj2) != 0):\n",
    "            r = 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_obj(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and obj1 in text):\n",
    "        r += 1.0\n",
    "    if (len(obj2) != 0 and obj2 in text):\n",
    "        r += 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_asp_pred(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    o1 = (len(obj1) != 0 and obj1 in text)\n",
    "    o2 = (len(obj2) != 0 and obj2 in text)\n",
    "    if (o1 or o2):\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 0.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 0.5\n",
    "    return r\n",
    "\n",
    "def make_scores_obj(query, answers):\n",
    "    print (\"make_scores_obj\")\n",
    "    (obj1, obj2, pred, asp) = extract_objs_asp(extr, query)\n",
    "    print (\"in make scores\", obj1, obj2, pred, asp)\n",
    "    scores_answers = [count_score(cleanhtml(answer), (obj1, obj2, pred, asp)) for answer in answers]\n",
    "    return scores_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_objects_predicates tags ['O', 'O', 'B-Predicate', 'B-Object', 'B-Aspect', 'O', 'B-Object', 'B-Aspect']\n",
      "extract_objects_predicates words ['What', 'is', 'better', 'Google', 'search', 'or', 'Yahoo', 'search']\n",
      "2\n",
      "ind, word 2 better\n",
      "old start, starts -1 set()\n",
      "string   salary is higher basketball or soccer players\n",
      "['Google', 'Yahoo']\n",
      "['better']\n",
      "['search', 'search']\n",
      "len(objects) 2\n"
     ]
    }
   ],
   "source": [
    "my_extractor.extract_objects_predicates(\"What is better Google search or Yahoo search\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import extractorRoberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/cqas/external_pretrained_models/roberta.hdf5\n",
      "/notebook/cqas/external_pretrained_models/vocab_dir\n",
      "encoder loaded\n",
      "indexer loaded\n",
      "model loaded\n",
      "reader loaded\n",
      "loaded extractors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_extractor = extractorRoberta(my_device = device, model_path = '/notebook/cqas/external_pretrained_models/')\n",
    "print (\"loaded extractors\")\n",
    "\n",
    "lambd_extract = lambda qry: extract_objs_asp(my_extractor, qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 24 23:06:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 66%   65C    P2   261W / 260W |  10408MiB / 11019MiB |     78%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 68%   66C    P2   185W / 260W |  10852MiB / 11019MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   40C    P2    55W / 260W |   1464MiB / 11019MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 74%   69C    P2   121W / 260W |   7120MiB / 11019MiB |     68%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 69%   67C    P2   213W / 260W |  10810MiB / 11019MiB |     77%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 34%   48C    P2    64W / 260W |   2785MiB / 11019MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 40%   49C    P2    63W / 260W |   1344MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 63%   64C    P2   254W / 260W |   7934MiB / 11019MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-8f8921f57a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mobj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'request' is not defined"
     ]
    }
   ],
   "source": [
    "input_string = request.get_data().decode('UTF-8')\n",
    "my_extractor.from_string(input_string)\n",
    "obj1, obj2, predicates, aspects = my_extractor.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.text import scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>sex may or may not include penetration. differ...</td>\n",
       "      <td>2406.73410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1811wb-62-08418</td>\n",
       "      <td>having sex and a rape are two completely d...</td>\n",
       "      <td>2396.66970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>home &amp;gt; articles &amp;gt; sex, sexuality &amp;amp; p...</td>\n",
       "      <td>2270.98270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1311wb-38-04762</td>\n",
       "      <td>home &amp;gt;&amp;gt;&amp;gt; sex education 2.0 &amp;gt;&amp;gt;&amp;g...</td>\n",
       "      <td>2096.91850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200tw-85-01106</td>\n",
       "      <td>things have changed so much and it has been ye...</td>\n",
       "      <td>2010.64640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36778</th>\n",
       "      <td>39</td>\n",
       "      <td>is java code more readable than code written i...</td>\n",
       "      <td>clueweb12-1215wb-42-08258</td>\n",
       "      <td>this is a clever trick. the real complexity oc...</td>\n",
       "      <td>943.83185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36779</th>\n",
       "      <td>39</td>\n",
       "      <td>is java code more readable than code written i...</td>\n",
       "      <td>clueweb12-1215wb-28-18173</td>\n",
       "      <td>this is a clever trick. the real complexity oc...</td>\n",
       "      <td>943.83185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36780</th>\n",
       "      <td>39</td>\n",
       "      <td>is java code more readable than code written i...</td>\n",
       "      <td>clueweb12-1215wb-30-05633</td>\n",
       "      <td>this is a clever trick. the real complexity oc...</td>\n",
       "      <td>943.83185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>39</td>\n",
       "      <td>is java code more readable than code written i...</td>\n",
       "      <td>clueweb12-1215wb-30-05635</td>\n",
       "      <td>this is a clever trick. the real complexity oc...</td>\n",
       "      <td>943.83185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36782</th>\n",
       "      <td>39</td>\n",
       "      <td>is java code more readable than code written i...</td>\n",
       "      <td>clueweb12-1215wb-39-09776</td>\n",
       "      <td>this is a clever trick. the real complexity oc...</td>\n",
       "      <td>943.83185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36783 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                                              query  \\\n",
       "0       1        what is the difference between sex and love   \n",
       "1       1        what is the difference between sex and love   \n",
       "2       1        what is the difference between sex and love   \n",
       "3       1        what is the difference between sex and love   \n",
       "4       1        what is the difference between sex and love   \n",
       "...    ..                                                ...   \n",
       "36778  39  is java code more readable than code written i...   \n",
       "36779  39  is java code more readable than code written i...   \n",
       "36780  39  is java code more readable than code written i...   \n",
       "36781  39  is java code more readable than code written i...   \n",
       "36782  39  is java code more readable than code written i...   \n",
       "\n",
       "                           docno  \\\n",
       "0      clueweb12-1214wb-88-29751   \n",
       "1      clueweb12-1811wb-62-08418   \n",
       "2      clueweb12-0200wb-79-18105   \n",
       "3      clueweb12-1311wb-38-04762   \n",
       "4      clueweb12-0200tw-85-01106   \n",
       "...                          ...   \n",
       "36778  clueweb12-1215wb-42-08258   \n",
       "36779  clueweb12-1215wb-28-18173   \n",
       "36780  clueweb12-1215wb-30-05633   \n",
       "36781  clueweb12-1215wb-30-05635   \n",
       "36782  clueweb12-1215wb-39-09776   \n",
       "\n",
       "                                                    text  baseline_scores  \\\n",
       "0      sex may or may not include penetration. differ...       2406.73410   \n",
       "1      having sex and a rape are two completely d...       2396.66970   \n",
       "2      home &gt; articles &gt; sex, sexuality &amp; p...       2270.98270   \n",
       "3      home &gt;&gt;&gt; sex education 2.0 &gt;&gt;&g...       2096.91850   \n",
       "4      things have changed so much and it has been ye...       2010.64640   \n",
       "...                                                  ...              ...   \n",
       "36778  this is a clever trick. the real complexity oc...        943.83185   \n",
       "36779  this is a clever trick. the real complexity oc...        943.83185   \n",
       "36780  this is a clever trick. the real complexity oc...        943.83185   \n",
       "36781  this is a clever trick. the real complexity oc...        943.83185   \n",
       "36782  this is a clever trick. the real complexity oc...        943.83185   \n",
       "\n",
       "       is_retrieved  ap_score  objs_score  \n",
       "0               0.0       0.0         0.0  \n",
       "1               0.0       0.0         0.0  \n",
       "2               0.0       0.0         0.0  \n",
       "3               0.0       0.0         0.0  \n",
       "4               0.0       0.0         0.0  \n",
       "...             ...       ...         ...  \n",
       "36778           1.0       0.0         0.0  \n",
       "36779           1.0       0.0         0.0  \n",
       "36780           1.0       0.0         0.0  \n",
       "36781           1.0       0.0         0.0  \n",
       "36782           1.0       0.0         0.0  \n",
       "\n",
       "[36783 rows x 8 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head(-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "textscorerTf = text.scorer(body_attr=\"text\", wmodel='BM25', sort=False)\n",
    "rtr_bm = textscorerTf.transform(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1412wb-36-28142</td>\n",
       "      <td>0</td>\n",
       "      <td>23.759399</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>1</td>\n",
       "      <td>23.572710</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>2</td>\n",
       "      <td>23.162551</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0601wb-52-24897</td>\n",
       "      <td>3</td>\n",
       "      <td>21.569264</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0706wb-92-20025</td>\n",
       "      <td>4</td>\n",
       "      <td>21.569264</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno  rank      score  \\\n",
       "0   1  clueweb12-1412wb-36-28142     0  23.759399   \n",
       "1   1  clueweb12-0200wb-79-18105     1  23.572710   \n",
       "2   1  clueweb12-1214wb-88-29751     2  23.162551   \n",
       "3   1  clueweb12-0601wb-52-24897     3  21.569264   \n",
       "4   1  clueweb12-0706wb-92-20025     4  21.569264   \n",
       "\n",
       "                                         query  \n",
       "0  what is the difference between sex and love  \n",
       "1  what is the difference between sex and love  \n",
       "2  what is the difference between sex and love  \n",
       "3  what is the difference between sex and love  \n",
       "4  what is the difference between sex and love  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtr_bm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featured_dataset(some_df):\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='BM25', sort=False)\n",
    "    rtr_bm = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='Tf')\n",
    "    rtr_tf = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='PL2')\n",
    "    rtr_pl2 = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='DFIC')\n",
    "    rtr_dfic = textscorerTf.transform(some_df)\n",
    "    \n",
    "    rtr_pl2_for_merge = rtr_pl2[['qid', 'docno', 'score']]\n",
    "    rtr_pl2_for_merge = rtr_pl2_for_merge.rename(columns={\"score\": \"score_pl2\"})\n",
    "    \n",
    "    rtr_tf_for_merge = rtr_tf[['qid', 'docno', 'score']]\n",
    "    rtr_tf_for_merge = rtr_tf_for_merge.rename(columns={\"score\": \"score_tf\"})\n",
    "    \n",
    "    rtr_bm_for_merge = rtr_bm[['qid', 'docno', 'score']]\n",
    "    rtr_bm_for_merge = rtr_bm_for_merge.rename(columns={\"score\": \"score_bm\"})\n",
    "    \n",
    "    rtr_dfic_for_merge = rtr_dfic[['qid', 'docno', 'score']]\n",
    "    rtr_dfic_for_merge = rtr_dfic_for_merge.rename(columns={\"score\": \"score_dfic\"})\n",
    "    \n",
    "    result = pd.merge(rtr_pl2_for_merge, rtr_tf_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_bm_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_dfic_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, some_df, on=[\"qid\", \"docno\"])\n",
    "    zipped = [result[\"score_pl2\"], result[\"score_tf\"], result[\"score_bm\"], result[\"score_dfic\"], result['baseline_scores'], result[\"is_retrieved\"], result[\"ap_score\"], result[\"objs_score\"]]\n",
    "    unzipped_object = zip(*zipped)\n",
    "    unzipped_list = list(unzipped_object)\n",
    "    list_of_features = [np.array(elem) for elem in unzipped_list]\n",
    "    result['features'] = list_of_features\n",
    "    return result\n",
    "\n",
    "test_ds = create_featured_dataset(info_df_test)\n",
    "result = create_featured_dataset(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'docno', 'score_pl2', 'score_tf', 'score_bm', 'score_dfic',\n",
       "       'query', 'text', 'baseline_scores', 'is_retrieved', 'ap_score',\n",
       "       'objs_score', 'features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(test_ds['qid']) == set(qrels_df_test['qid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking with LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "#tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "#pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "#pipeline = (rtr_tf ** rtr_pl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranks1(rtr : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Canonical method for adding a rank column which is calculated based on the score attribute\n",
    "        for each query. Note that the dataframe is NOT sorted by this operation.\n",
    "        Arguments\n",
    "            df: dataframe to create rank attribute for\n",
    "    \"\"\"\n",
    "    rtr.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
    "    if len(rtr) == 0:\n",
    "        rtr[\"rank\"] = pd.Series(index=rtr.index, dtype='int64')\n",
    "        return rtr\n",
    "    print (0)\n",
    "    # -1 assures that first rank will be FIRST_RANK\n",
    "    rtr[\"rank\"] = rtr.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + 1\n",
    "    print (1)\n",
    "    if True:\n",
    "        rtr.sort_values([\"qid\", \"rank\"], ascending=[True,True], inplace=True)\n",
    "    return rtr\n",
    "\n",
    "def transform(model, test_DF):\n",
    "    \"\"\"\n",
    "    Predicts the scores for the given topics.\n",
    "\n",
    "    Args:\n",
    "        topicsTest(DataFrame): A dataframe with the test topics.\n",
    "    \"\"\"\n",
    "    test_DF = test_DF.copy()\n",
    "\n",
    "    # check for change in number of features\n",
    "    found_numf = test_DF.iloc[0].features.shape[0]\n",
    "    if model.num_f is not None:\n",
    "        if found_numf != model.num_f:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (model.num_f, found_numf))\n",
    "    if hasattr(model.learner, 'feature_importances_'):\n",
    "        if len(model.learner.feature_importances_) != found_numf:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (len(model.learner.feature_importances_), found_numf))\n",
    "\n",
    "    test_DF[\"score\"] = model.learner.predict(np.stack(test_DF[\"features\"].values))\n",
    "    return add_ranks1(test_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=20)\n",
    "rf_pipe = pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(result, qrels_df)\n",
    "answs = transform(rf_pipe, test_ds)\n",
    "#pt.Experiment([result, rf_pipe], result, qrels_df, [\"map\"], names=[\"BM25 Baseline\", \"LTR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qrels(name, rtr):\n",
    "    qids = rtr['qid']\n",
    "    Q0s = [0 for elem in qids]\n",
    "    docs = rtr['docno']\n",
    "    scores = rtr['score']\n",
    "    ranks = rtr['rank']\n",
    "    tags = [name for elem in qids]\n",
    "    common_list = list(zip(qids, Q0s, docs, ranks, scores, tags))\n",
    "    with open(name +'.qrels', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "    print (\"written \" + name +'.qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written RF.qrels\n"
     ]
    }
   ],
   "source": [
    "write_qrels(\"RF\", answs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written standart_test.qrels\n"
     ]
    }
   ],
   "source": [
    "rtr = qrels_df_test\n",
    "qids = rtr['qid']\n",
    "Q0s = [0 for elem in qids]\n",
    "docs = rtr['docno']\n",
    "ranks = rtr['label']\n",
    "\n",
    "common_list = list(zip(qids, Q0s, docs, ranks))\n",
    "with open(\"standart_test\" +'.qrels', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s %s %s' % x for x in common_list))\n",
    "print (\"written \" + 'standart' +'_test.qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1608wb-39-15329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700tw-30-03487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0811wb-62-19220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno label\n",
       "0  40  clueweb12-1608wb-39-15329     0\n",
       "1  40  clueweb12-1700tw-30-03487     0\n",
       "2  40  clueweb12-0811wb-62-19220     0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_qrels(\"standart\", qrels_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cord19' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-6e780ff18424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcord19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cord19' is not defined"
     ]
    }
   ],
   "source": [
    "cord19.get_topics(variant='train').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19 = pt.datasets.get_dataset('antique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cord19' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b25d613a2022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcord19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mqrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcord19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qrels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cord19' is not defined"
     ]
    }
   ],
   "source": [
    "topics = cord19.get_topics(variant='train')\n",
    "qrels = cord19.get_qrels(variant='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pt_index_path = './terrier_cord19_blocks'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = indexer.index(cord19.get_corpus_iter(), \n",
    "                              fields=('abstract',), \n",
    "                              meta=('docno',))\n",
    "\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "pl = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "dfic = pt.BatchRetrieve(index, wmodel=\"DFIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-01998d7cdd19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_qrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_qrels\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_topics, test_topics = train_test_split(topics, test_size=15, random_state=42)\n",
    "train_qrels, test_qrels =  train_test_split(qrels, test_size=15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltr_feats1 = (bm25 ** tf ** pl ** dfic)\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"TF\", 'pl', 'dfic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# this configures XGBoost as LambdaMART\n",
    "lmart_x = xgb.sklearn.XGBRanker(objective='rank:ndcg',\n",
    "      learning_rate=0.1,\n",
    "      gamma=1.0,\n",
    "      min_child_weight=0.1,\n",
    "      max_depth=6,\n",
    "      verbose=2,\n",
    "      random_state=42)\n",
    "\n",
    "rf_lgbm = pt.ltr.apply_learned_model(lmart_x, form=\"ltr\")\n",
    "rf_lgbm.fit(result, qrels_df, topics_and_results_Valid = test_ds, qrelsValid = qrels_df_test)\n",
    "answs = transform(rf_lgbm, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance according LightGBM and XGboost\n",
    "\n",
    "* f0: result[\"score_pl2\"], 5, 1.76\n",
    "\n",
    "* f1: result[\"score_tf\"], 0, 1.19\n",
    "* f2: result[\"score_bm\"], 3, 1.51\n",
    "* f3: result[\"score_dfic\"], 3, 2.3\n",
    "* f4: result['baseline_scores'], 19, 23.82\n",
    "* f5: result[\"is_retrieved\"], 0, 0\n",
    "* f6: result[\"ap_score\"], 3,  1.66\n",
    "* f7: result[\"objs_score\"]0, 1.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f4': 23.82235418611851,\n",
       " 'f3': 2.3183860100909097,\n",
       " 'f0': 1.7651199528500001,\n",
       " 'f1': 1.19102281,\n",
       " 'f7': 1.51639706,\n",
       " 'f6': 1.6681483940833335,\n",
       " 'f2': 0.9739630702}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_lgbm.learner.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=12,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=20,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "rf_lgbm = pt.ltr.apply_learned_model(lmart_l, form=\"ltr\")\n",
    "rf_lgbm.fit(result, qrels_df, topics_and_results_Valid = test_ds, qrelsValid = qrels_df_test)\n",
    "answs = transform(rf_lgbm, test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  3,  3, 19,  0,  3,  0], dtype=int32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_lgbm.learner.booster_.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written RF.qrels\n"
     ]
    }
   ],
   "source": [
    "write_qrels(\"RF\", answs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers' score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_custom import make_scores_transformers, run_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_ in range(11):\n",
    "    run_baseline(head = head_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import onir_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement onir_pt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for onir_pt\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install onir_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
    "#!pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbert = onir_pt.reranker('vanilla_transformer', 'bert', text_field='text', vocab_config={'train': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
