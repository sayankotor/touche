{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "PyTerrier 0.5.0 has loaded Terrier 5.4 (built by craigm on 2021-01-16 14:17)\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  print (\"not\")  \n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade fastrank lightgbm \n",
    "#!pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/cqas/external_pretrained_models/roberta.hdf5\n",
      "/notebook/cqas/external_pretrained_models/vocab_dir\n",
      "encoder loaded\n",
      "indexer loaded\n",
      "model path  /notebook/cqas/external_pretrained_models/roberta.hdf5\n",
      "model loaded\n",
      "reader loaded\n",
      "loaded extractors\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from my_functions import extractorRoberta\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_extractor = extractorRoberta(my_device = device, model_path = '/notebook/cqas/external_pretrained_models/')\n",
    "print (\"loaded extractors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objs_asp(model_for_extraction, input_string):\n",
    "    model_for_extraction.from_string(input_string)\n",
    "    obj1, obj2, predicates, aspects = model_for_extraction.get_params()\n",
    "    return (obj1.lower(), obj2.lower(), predicates, aspects)\n",
    "\n",
    "\n",
    "def count_score1(text, nlu_tuple):\n",
    "    (obj1, obj2, pred, asp) = nlu_tuple\n",
    "    r = 1.0\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (len(pred) != 0):\n",
    "            pred = re.sub('[!#?,.:\";]', '', pred[0])\n",
    "            if (obj1 in text and obj2 in text and pred in text):\n",
    "                r += 1.0\n",
    "        if (len(asp) != 0):\n",
    "            asp = re.sub('[!#?,.:\";]', '', asp[0])\n",
    "            if (obj1 in text and obj2 in text and asp in text):\n",
    "                r += 1.0\n",
    "        elif (obj1 in text and obj2 in text):\n",
    "            r = 1.5\n",
    "        elif (obj1 in text or obj2 in text):\n",
    "            r = 1.2\n",
    "    else:\n",
    "        if (obj1) in text or (obj2) in text:\n",
    "            r = 1.2\n",
    "    return r\n",
    "\n",
    "def count_score_nlu(nlu_tuple):\n",
    "    if (len(nlu_tuple[0]) == 0):\n",
    "        return 0.0\n",
    "    else: return 1.0\n",
    "\n",
    "\n",
    "def count_score(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and len(obj2) != 0):\n",
    "        if (obj1 in text):\n",
    "            r += 1.0\n",
    "        if (obj2 in text):\n",
    "            r += 1.0\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 1.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 1.0\n",
    "    else:\n",
    "        if ((obj1) in text and len(obj1)!= 0) or (obj2 in text and len(obj2) != 0):\n",
    "            r = 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_obj(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    if (len(obj1) != 0 and obj1 in text):\n",
    "        r += 1.0\n",
    "    if (len(obj2) != 0 and obj2 in text):\n",
    "        r += 1.0\n",
    "    return r\n",
    "\n",
    "def count_score_asp_pred(text, nlu_tuple):\n",
    "    (obj1, obj2, preds, asps) = nlu_tuple\n",
    "    r = 0.0\n",
    "    text = cleanhtml(text)\n",
    "    o1 = (len(obj1) != 0 and obj1 in text)\n",
    "    o2 = (len(obj2) != 0 and obj2 in text)\n",
    "    if (o1 or o2):\n",
    "        for asp in asps:\n",
    "            if asp in text:\n",
    "                r += 0.5\n",
    "        for pred in preds:\n",
    "            if pred in text:\n",
    "                r += 0.5\n",
    "    return r\n",
    "\n",
    "\n",
    "def make_scores_obj(query, answers):\n",
    "    print (\"make_scores_obj\")\n",
    "    (obj1, obj2, pred, asp) = extract_objs_asp(extr, query)\n",
    "    print (\"in make scores\", obj1, obj2, pred, asp)\n",
    "    scores_answers = [count_score(cleanhtml(answer), (obj1, obj2, pred, asp)) for answer in answers]\n",
    "    return scores_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7fa9d6071eb0>]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "def read_xml(filename):\n",
    "    # convert file filename to list of tuples (number_of_topic, title_of_topic) \n",
    "    # input: filename string\n",
    "    # output: list of corresponding tuples\n",
    "    answer_list = []\n",
    "    xmldoc = minidom.parse(filename)\n",
    "    itemlist = xmldoc.getElementsByTagName('topics')\n",
    "    print(len(itemlist))\n",
    "    print(itemlist)\n",
    "    topic_list = itemlist[0].getElementsByTagName('topic')\n",
    "    print (len(topic_list))\n",
    "    for topic in topic_list:\n",
    "        tuple_for_add = tuple((topic.getElementsByTagName('number')[0].firstChild.nodeValue, topic.getElementsByTagName('title')[0].firstChild.nodeValue))\n",
    "        answer_list.append(tuple_for_add)\n",
    "    return answer_list\n",
    "\n",
    "topics_2020 = read_xml('topics-task-2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('31', '\\nWhich has more caffeine, coffee or tea?\\n'),\n",
       " ('32', '\\nWhich is better, LED or LCD Reception Displays?\\n'),\n",
       " ('33', '\\nWhat is better: ASP or PHP?\\n'),\n",
       " ('34',\n",
       "  '\\nWhat is better for the environment, a real or a fake Christmas tree?\\n'),\n",
       " ('35', '\\nDo you prefer tampons or pads?\\n'),\n",
       " ('36', '\\nWhat IDE is better for Java: NetBeans or Eclipse?\\n'),\n",
       " ('37',\n",
       "  '\\nIs OpenGL better than Direct3D in terms of portability to different platforms?\\n'),\n",
       " ('38',\n",
       "  '\\nWhat are the differences between MySQL and PostgreSQL in performance?\\n'),\n",
       " ('39', '\\nIs Java code more readable than code written in Scala?\\n'),\n",
       " ('40',\n",
       "  '\\nWhich operating system has better performance: Windows 7 or Windows 8?\\n'),\n",
       " ('41', '\\nWhich smartphone has a better battery life: Xperia or iPhone?\\n'),\n",
       " ('42', '\\nWhich four wheel truck is better: Ford or Toyota?\\n'),\n",
       " ('43',\n",
       "  '\\nShould I prefer a Leica camera over Nikon for portrait photographs?\\n'),\n",
       " ('44', '\\nWhich company has a larger capitalization: Apple or Microsoft?\\n'),\n",
       " ('45', '\\nWhich laptop has a better durability: HP or Dell?\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_2020[30:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#r = requests.post('http://10.30.99.211:8261/gpt_small', data = \"What is better for deep learning Python or Matlab?\")\n",
    "#print (r.status_code)\n",
    "import requests\n",
    "from xml.dom import minidom\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read retireved documents and qrels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('/notebook/touche/list_of_un_answ.pkl', 'rb') as f:\n",
    "    answers_2020 = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/touche2021/touche2020-task2-relevance-withbaseline.qrels', 'r') as f:\n",
    "    qrels_lines = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "qrels = [x.strip().split() for x in qrels_lines] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create qrels dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "for elem in qrels:\n",
    "    query, noninf, docno, rank = elem\n",
    "    if (query in qrels_dict.keys()):\n",
    "        qrels_dict[query].append((docno, rank))\n",
    "    else:\n",
    "        qrels_dict[query] = []\n",
    "        qrels_dict[query].append((docno, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clueweb12-0815wb-21-00423', '2'),\n",
       " ('clueweb12-0108wb-27-03924', '2'),\n",
       " ('clueweb12-0001wb-84-27874', '2'),\n",
       " ('clueweb12-0004wb-25-35255', '2'),\n",
       " ('clueweb12-0007wb-69-30265', '2'),\n",
       " ('clueweb12-0103wb-12-24884', '1'),\n",
       " ('clueweb12-0810wb-94-06721', '2'),\n",
       " ('clueweb12-0101wb-61-12535', '1'),\n",
       " ('clueweb12-0311wb-03-10308', '2'),\n",
       " ('clueweb12-1010wb-21-13067', '0'),\n",
       " ('clueweb12-0010wb-73-33411', '2'),\n",
       " ('clueweb12-1313wb-65-05083', '2'),\n",
       " ('clueweb12-1411wb-38-10889', '1'),\n",
       " ('clueweb12-1414wb-05-16226', '2'),\n",
       " ('clueweb12-1010wb-84-02332', '0'),\n",
       " ('clueweb12-1516wb-43-24623', '1'),\n",
       " ('clueweb12-1406wb-06-02996', '1'),\n",
       " ('clueweb12-0109wb-54-20272', '0'),\n",
       " ('clueweb12-0309wb-64-08181', '2'),\n",
       " ('clueweb12-0310wb-87-04609', '1')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_dict['34'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict['34'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(304.44406,\n",
       "  'clueweb12-1010wb-84-02332',\n",
       "  'voice in the dark - part 4',\n",
       "  'friday tips volume twenty five » focus organic.com – this entry is part 25 of 103 in the series eco-friendly friday november 28th’s tip christmas trees: stuck between choosing a real christmas tree or a fake one?')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [elem for elem in answers_2020['34'] if elem[1] == 'clueweb12-1010wb-84-02332']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(304.44406,\n",
       "  'clueweb12-1010wb-84-02332',\n",
       "  'voice in the dark - part 4',\n",
       "  'friday tips volume twenty five » focus organic.com – this entry is part 25 of 103 in the series eco-friendly friday november 28th’s tip christmas trees: stuck between choosing a real christmas tree or a fake one?')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [elem for elem in answers_2020['34'] if elem[1] == 'clueweb12-1010wb-84-02332']\n",
    "a # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1652.0702,\n",
       "  'clueweb12-0001wb-84-27874',\n",
       "  'christmas tree allergy - avoid pine, fir, spruce, or artificial christmas',\n",
       "  'how to avoid allergies during christmas tree season. about.com health&#x27;s disease and condition content is reviewed by our medical review board real or artificial? there is so much confusing information out there about which is better for your health and the environment.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [elem for elem in answers_2020['34'] if elem[1] == 'clueweb12-0001wb-84-27874']\n",
    "a # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2384.4077,\n",
       "  'clueweb12-0310wb-87-04609',\n",
       "  'is a fake christmas tree the &#x27;green&#x27; choice? - msn money',\n",
       "  'you may think you&#x27;re saving a tree, but the plastic alternative has problems too. while the debate rages on, we&#x27;ve got some better ways to help the planet this christmas. which is &quot;greener,&quot; an artificial christmas tree or a real one?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [elem for elem in answers_2020['34'] if elem[1] == 'clueweb12-0310wb-87-04609']\n",
    "a # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(s):\n",
    "    s = re.sub(r'[^\\w\\s]','',s)\n",
    "    return s\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '0', 'clueweb12-0001wb-05-12311', '0'],\n",
       " ['1', '0', 'clueweb12-1811wb-62-08424', '1'],\n",
       " ['1', '0', 'clueweb12-1811wb-62-08423', '1']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0', 'clueweb12-1214wb-88-29751', '2']\n"
     ]
    }
   ],
   "source": [
    "for elem in qrels:\n",
    "    if (elem[2] == 'clueweb12-1214wb-88-29751'):\n",
    "        print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qrels_df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8c14b2dcdda8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqrels_df_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qrels_df_test' is not defined"
     ]
    }
   ],
   "source": [
    "qrels_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create proper pandas df documents and qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "info_df = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"],dtype=object)\n",
    "info_df_test = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"], dtype=object)\n",
    "qrels_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"],dtype=object)\n",
    "qrels_df_test = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"],dtype=object)\n",
    "\n",
    "for elem in topics_2020:\n",
    "        qid, query = elem[0], elem[1].strip('\\n')\n",
    "        query = re.sub(r'[^\\w\\s]','',query)\n",
    "        query = cleanhtml(query)\n",
    "        my_extractor.from_string(query)\n",
    "        structures = my_extractor.get_params()\n",
    "\n",
    "        for ind, answer in enumerate(answers_2020[qid]):\n",
    "            docno = answer[1]\n",
    "            score = answer[0]\n",
    "            text = answer[3]\n",
    "            label = [el[3] for el in qrels if el[2]==docno]\n",
    "            nlu_score = count_score(text, structures)\n",
    "            objs_score = count_score_obj(text, structures)\n",
    "            ap_score = count_score_asp_pred(text, structures)\n",
    "            is_retrieved = count_score_nlu(structures)\n",
    "            if (True):\n",
    "                df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"text\":text, \"baseline_scores\":score, \"is_retrieved\":is_retrieved, \"ap_score\":ap_score, \"objs_score\":objs_score}\n",
    "                if int(qid) < 40:          \n",
    "                    info_df = info_df.append(df_row, ignore_index= True)\n",
    "                else:\n",
    "                    info_df_test = info_df_test.append(df_row, ignore_index= True)\n",
    "                \n",
    "                for qrel in qrels_dict[qid]:\n",
    "                    docno, label = qrel\n",
    "                    df_row = {\"qid\":qid, \"docno\":docno, \"label\":label}\n",
    "                if (int(qid) < 40):\n",
    "                    qrels_df = qrels_df.append(df_row, ignore_index= True)\n",
    "                else:\n",
    "                    qrels_df_test = qrels_df_test.append(df_row, ignore_index= True)\n",
    "\n",
    "\n",
    "\n",
    "#textscorerTf = pt.text.scorer(body_attr=\"text\", wmodel=\"Tf\")\n",
    "#rtr = textscorerTf.transform("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36798 36798\n"
     ]
    }
   ],
   "source": [
    "print(len(info_df),len(qrels_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>sex may or may not include penetration. differ...</td>\n",
       "      <td>2406.7341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1811wb-62-08418</td>\n",
       "      <td>having ’sex’ and a ‘rape’ are two completely d...</td>\n",
       "      <td>2396.6697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>home &amp;gt; articles &amp;gt; sex, sexuality &amp;amp; p...</td>\n",
       "      <td>2270.9827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-1311wb-38-04762</td>\n",
       "      <td>home &amp;gt;&amp;gt;&amp;gt; sex education 2.0 &amp;gt;&amp;gt;&amp;g...</td>\n",
       "      <td>2096.9185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>clueweb12-0200tw-85-01106</td>\n",
       "      <td>things have changed so much and it has been ye...</td>\n",
       "      <td>2010.6464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                                        query                      docno  \\\n",
       "0   1  what is the difference between sex and love  clueweb12-1214wb-88-29751   \n",
       "1   1  what is the difference between sex and love  clueweb12-1811wb-62-08418   \n",
       "2   1  what is the difference between sex and love  clueweb12-0200wb-79-18105   \n",
       "3   1  what is the difference between sex and love  clueweb12-1311wb-38-04762   \n",
       "4   1  what is the difference between sex and love  clueweb12-0200tw-85-01106   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  sex may or may not include penetration. differ...        2406.7341   \n",
       "1  having ’sex’ and a ‘rape’ are two completely d...        2396.6697   \n",
       "2  home &gt; articles &gt; sex, sexuality &amp; p...        2270.9827   \n",
       "3  home &gt;&gt;&gt; sex education 2.0 &gt;&gt;&g...        2096.9185   \n",
       "4  things have changed so much and it has been ye...        2010.6464   \n",
       "\n",
       "   is_retrieved  ap_score  objs_score  \n",
       "0           0.0       0.0         0.0  \n",
       "1           0.0       0.0         0.0  \n",
       "2           0.0       0.0         0.0  \n",
       "3           0.0       0.0         0.0  \n",
       "4           0.0       0.0         0.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.text import scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featured_dataset(some_df):\n",
    "    from pyterrier import text\n",
    "    from pyterrier.text import scorer\n",
    "    print (0)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='BM25', sort=False)\n",
    "    rtr_bm = textscorerTf.transform(some_df)\n",
    "    print (1)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='Tf')\n",
    "    rtr_tf = textscorerTf.transform(some_df)\n",
    "    print (2)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='PL2')\n",
    "    rtr_pl2 = textscorerTf.transform(some_df)\n",
    "    print (3)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='DFIC')\n",
    "    rtr_dfic = textscorerTf.transform(some_df)\n",
    "    print (4)\n",
    "    rtr_pl2_for_merge = rtr_pl2[['qid', 'docno', 'score']]\n",
    "    rtr_pl2_for_merge = rtr_pl2_for_merge.rename(columns={\"score\": \"score_pl2\"})\n",
    "    print (5)\n",
    "    rtr_tf_for_merge = rtr_tf[['qid', 'docno', 'score']]\n",
    "    rtr_tf_for_merge = rtr_tf_for_merge.rename(columns={\"score\": \"score_tf\"})\n",
    "    print (6)\n",
    "    rtr_bm_for_merge = rtr_bm[['qid', 'docno', 'score']]\n",
    "    rtr_bm_for_merge = rtr_bm_for_merge.rename(columns={\"score\": \"score_bm\"})\n",
    "    print (7)\n",
    "    rtr_dfic_for_merge = rtr_dfic[['qid', 'docno', 'score']]\n",
    "    rtr_dfic_for_merge = rtr_dfic_for_merge.rename(columns={\"score\": \"score_dfic\"})\n",
    "    print (8)\n",
    "    result = pd.merge(rtr_pl2_for_merge, rtr_tf_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_bm_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_dfic_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, some_df, on=[\"qid\", \"docno\"])\n",
    "    zipped = [result[\"score_pl2\"], result[\"score_tf\"], result[\"score_bm\"], result[\"score_dfic\"], result['baseline_scores'], result[\"is_retrieved\"], result[\"ap_score\"], result[\"objs_score\"]]\n",
    "    unzipped_object = zip(*zipped)\n",
    "    unzipped_list = list(unzipped_object)\n",
    "    list_of_features = [np.array(elem) for elem in unzipped_list]\n",
    "    result['features'] = list_of_features\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info_df['qid'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "result = create_featured_dataset(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "test_ds = create_featured_dataset(info_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno label\n",
       "0  40  clueweb12-0500tw-35-13169     1\n",
       "1  40  clueweb12-0500tw-35-13169     1\n",
       "2  40  clueweb12-0500tw-35-13169     1\n",
       "3  40  clueweb12-0500tw-35-13169     1\n",
       "4  40  clueweb12-0500tw-35-13169     1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.to_pickle(\"test_ds.pkl\")\n",
    "qrels_df_test.to_pickle(\"qrels_df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1', '2'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(qrels_df_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qrels(output_dir, name, rtr):\n",
    "    print (\"rtr in write qrels \", rtr.head())\n",
    "    qids = rtr['qid']\n",
    "    Q0s = [0 for elem in qids]\n",
    "    docs = rtr['docno']\n",
    "    ranks = rtr['rank']\n",
    "    score = rtr['score']\n",
    "    tags = [name for elem in qids]\n",
    "    common_list = list(zip(qids, Q0s, docs, ranks, score, tags))\n",
    "    print (\"common_list \", common_list[:3])\n",
    "    with open(output_dir + name + '.qrels', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "    print (\"written \" + name +'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtr in write qrels    qid                      docno rank             score\n",
      "0  40  clueweb12-1100tw-55-05937    1  75.8093116910726\n",
      "1  40  clueweb12-1700wb-29-15033    2  69.9706035082827\n",
      "2  40  clueweb12-1700tw-30-03488    3  65.9923622033137\n",
      "3  40  clueweb12-1300tw-27-17207    4  51.7581117464051\n",
      "4  40  clueweb12-0500tw-35-13169    5   51.276620362775\n",
      "common_list  [('40', 0, 'clueweb12-1100tw-55-05937', '1', '75.8093116910726', 'baseline_test'), ('40', 0, 'clueweb12-1700wb-29-15033', '2', '69.9706035082827', 'baseline_test'), ('40', 0, 'clueweb12-1700tw-30-03488', '3', '65.9923622033137', 'baseline_test')]\n",
      "written baseline_test.txt\n"
     ]
    }
   ],
   "source": [
    "write_qrels(\"/notebook/touche2021/output\", \"baseline_test\", qrels_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/touche2021\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(test_ds['qid']) == set(qrels_df_test['qid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write B.beggins qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval/results/official2020_tracks.qrels/official2020_tracks.qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebook/touche2021\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "touche2021/runs-task-2/Bilbo Baggins/Run/run.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/notebook/touche2021/runs-task-2/Bilbo Baggins/Run/run.txt\") as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip().split() for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Q0',\n",
       " 'clueweb12-0004wb-91-15141',\n",
       " '21',\n",
       " '17.2093665154127',\n",
       " 'ul-t2-voelkerschlacht']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#info_df = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"],dtype=object)\n",
    "#info_df_test = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"baseline_scores\", \"is_retrieved\", \"ap_score\", \"objs_score\"], dtype=object)\n",
    "qrels_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"rank\", \"score\"],dtype=object)\n",
    "qrels_df_test = pd.DataFrame(columns=[\"qid\", \"docno\", \"rank\", \"score\"],dtype=object)\n",
    "\n",
    "for ind, answer in enumerate(content):\n",
    "    if (ind%1000 == 0):\n",
    "        print (ind)\n",
    "    docno = answer[2]\n",
    "    qid = answer[0]\n",
    "    rank = answer[3]\n",
    "    score = answer[4]\n",
    "    df_row = {\"qid\":qid, \"docno\":docno, \"rank\":rank, \"score\":score}\n",
    "    qrels_df_test = qrels_df_test.append(df_row, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qrels(output_dir, name, rtr):\n",
    "    print (\"rtr in write qrels \", rtr.head())\n",
    "    qids = rtr['qid']\n",
    "    Q0s = [0 for elem in qids]\n",
    "    docs = rtr['docno']\n",
    "    ranks = rtr['rank']\n",
    "    score = rtr['score']\n",
    "    tags = [name for elem in qids]\n",
    "    common_list = list(zip(qids, Q0s, docs, ranks, score, tags))\n",
    "    print (\"common_list \", common_list[:3])\n",
    "    with open(output_dir + name + '.qrels', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "    print (\"written \" + name +'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtr in write qrels    qid                      docno rank             score\n",
      "0   1  clueweb12-0010wb-73-33601    1  85.5517282896202\n",
      "1   1  clueweb12-1400tw-53-02910    2  73.9870753533032\n",
      "2   1  clueweb12-0307wb-05-31620    3  39.9813264103379\n",
      "3   1  clueweb12-0201wb-90-06213    4  37.1568135522378\n",
      "4   1  clueweb12-0506wb-26-02303    5  35.7838688603153\n",
      "common_list  [('1', 0, 'clueweb12-0010wb-73-33601', '1', '85.5517282896202', 'big_top_1'), ('1', 0, 'clueweb12-1400tw-53-02910', '2', '73.9870753533032', 'big_top_1'), ('1', 0, 'clueweb12-0307wb-05-31620', '3', '39.9813264103379', 'big_top_1')]\n",
      "written big_top_1.txt\n"
     ]
    }
   ],
   "source": [
    "write_qrels(\"/notebook/touche2021/output/\", \"big_top_1\", qrels_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval -q -c -m ndcg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1100tw-55-05937</td>\n",
       "      <td>1</td>\n",
       "      <td>75.8093116910726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700wb-29-15033</td>\n",
       "      <td>2</td>\n",
       "      <td>69.9706035082827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700tw-30-03488</td>\n",
       "      <td>3</td>\n",
       "      <td>65.9923622033137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1300tw-27-17207</td>\n",
       "      <td>4</td>\n",
       "      <td>51.7581117464051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0500tw-35-13169</td>\n",
       "      <td>5</td>\n",
       "      <td>51.276620362775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0700tw-80-23495</td>\n",
       "      <td>6</td>\n",
       "      <td>45.597702384667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1705wb-53-33166</td>\n",
       "      <td>7</td>\n",
       "      <td>42.9273937942786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1515wb-18-13784</td>\n",
       "      <td>8</td>\n",
       "      <td>41.6086756489246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1913wb-50-22864</td>\n",
       "      <td>9</td>\n",
       "      <td>38.5421679948438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1612wb-21-28532</td>\n",
       "      <td>10</td>\n",
       "      <td>37.2138925975698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0208wb-73-04482</td>\n",
       "      <td>11</td>\n",
       "      <td>37.178563224094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0302wb-36-06391</td>\n",
       "      <td>12</td>\n",
       "      <td>32.7514607464232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0700tw-61-06573</td>\n",
       "      <td>13</td>\n",
       "      <td>29.8778165293617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700tw-21-14945</td>\n",
       "      <td>14</td>\n",
       "      <td>29.3055528445858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1000tw-98-03284</td>\n",
       "      <td>15</td>\n",
       "      <td>29.1690974161704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                      docno rank             score\n",
       "0   40  clueweb12-1100tw-55-05937    1  75.8093116910726\n",
       "1   40  clueweb12-1700wb-29-15033    2  69.9706035082827\n",
       "2   40  clueweb12-1700tw-30-03488    3  65.9923622033137\n",
       "3   40  clueweb12-1300tw-27-17207    4  51.7581117464051\n",
       "4   40  clueweb12-0500tw-35-13169    5   51.276620362775\n",
       "5   40  clueweb12-0700tw-80-23495    6   45.597702384667\n",
       "6   40  clueweb12-1705wb-53-33166    7  42.9273937942786\n",
       "7   40  clueweb12-1515wb-18-13784    8  41.6086756489246\n",
       "8   40  clueweb12-1913wb-50-22864    9  38.5421679948438\n",
       "9   40  clueweb12-1612wb-21-28532   10  37.2138925975698\n",
       "10  40  clueweb12-0208wb-73-04482   11   37.178563224094\n",
       "11  40  clueweb12-0302wb-36-06391   12  32.7514607464232\n",
       "12  40  clueweb12-0700tw-61-06573   13  29.8778165293617\n",
       "13  40  clueweb12-1700tw-21-14945   14  29.3055528445858\n",
       "14  40  clueweb12-1000tw-98-03284   15  29.1690974161704"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df_test.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking with LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "#tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "#pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "#pipeline = (rtr_tf ** rtr_pl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranks1(rtr : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Canonical method for adding a rank column which is calculated based on the score attribute\n",
    "        for each query. Note that the dataframe is NOT sorted by this operation.\n",
    "        Arguments\n",
    "            df: dataframe to create rank attribute for\n",
    "    \"\"\"\n",
    "    rtr.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
    "    if len(rtr) == 0:\n",
    "        rtr[\"rank\"] = pd.Series(index=rtr.index, dtype='int64')\n",
    "        return rtr\n",
    "    print (0)\n",
    "    # -1 assures that first rank will be FIRST_RANK\n",
    "    rtr[\"rank\"] = rtr.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + 1\n",
    "    print (1)\n",
    "    if True:\n",
    "        rtr.sort_values([\"qid\", \"rank\"], ascending=[True,True], inplace=True)\n",
    "    return rtr\n",
    "\n",
    "def transform(model, test_DF):\n",
    "    \"\"\"\n",
    "    Predicts the scores for the given topics.\n",
    "\n",
    "    Args:\n",
    "        topicsTest(DataFrame): A dataframe with the test topics.\n",
    "    \"\"\"\n",
    "    test_DF = test_DF.copy()\n",
    "\n",
    "    # check for change in number of features\n",
    "    found_numf = test_DF.iloc[0].features.shape[0]\n",
    "    if model.num_f is not None:\n",
    "        if found_numf != model.num_f:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (model.num_f, found_numf))\n",
    "    if hasattr(model.learner, 'feature_importances_'):\n",
    "        if len(model.learner.feature_importances_) != found_numf:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (len(model.learner.feature_importances_), found_numf))\n",
    "\n",
    "    test_DF[\"score\"] = model.learner.predict(np.stack(test_DF[\"features\"].values))\n",
    "    test_DF[\"qid\"] = [int(elem) for elem in test_DF[\"qid\"]]\n",
    "    return add_ranks1(test_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=10)\n",
    "rf_pipe = pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(result, qrels_df)\n",
    "answs = transform(rf_pipe, test_ds)\n",
    "#pt.Experiment([result, rf_pipe], result, qrels_df, [\"map\"], names=[\"BM25 Baseline\", \"LTR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qrels(name, rtr):\n",
    "    qids = rtr['qid']\n",
    "    Q0s = [0 for elem in qids]\n",
    "    docs = rtr['docno']\n",
    "    #scores = rtr['label']\n",
    "    ranks = rtr['rank']\n",
    "    tags = [name for elem in qids]\n",
    "    common_list = list(zip(qids, Q0s, docs, ranks))\n",
    "    with open(name +'.qrels', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "    print (\"written \" + name +'_test.qrels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1055\n",
      "[LightGBM] [Info] Number of data points in the train set: 45473, number of used features: 8\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "[3]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "[4]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "[5]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "[6]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.818182\tvalid_0's ndcg@2: 0.818182\tvalid_0's ndcg@3: 0.818182\tvalid_0's ndcg@4: 0.818182\tvalid_0's ndcg@5: 0.818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "rf_pipe = pt.ltr.apply_learned_model(lmart_l, form=\"ltr\")\n",
    "\n",
    "#rf_pipe.learner.fit(np.stack(train_DF[\"features\"].values), train_DF[\"label\"].values)\n",
    "rf_pipe.fit(result, qrels_df, test_ds, qrels_df_test)\n",
    "#answs = transform(rf_pipe, test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-22712af9ff88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf_lgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_learned_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmart_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ltr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_qrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics_and_results_Valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrelsValid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_qrels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mansws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_topics' is not defined"
     ]
    }
   ],
   "source": [
    "rf_lgbm = pt.ltr.apply_learned_model(lmart_l, form=\"ltr\")\n",
    "rf_lgbm.fit(train_topics, train_qrels, topics_and_results_Valid = test_topics, qrelsValid = test_qrels)\n",
    "answs = transform(rf_lgbm, test_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>score_bm</th>\n",
       "      <th>score_dfic</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>11.626052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.103274</td>\n",
       "      <td>21.680909</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>home &amp;gt; articles &amp;gt; sex, sexuality &amp;amp; p...</td>\n",
       "      <td>2270.98270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.62605208595209, 9.0, 23.103273698299724, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>11.339902</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.708421</td>\n",
       "      <td>21.520754</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>sex may or may not include penetration. differ...</td>\n",
       "      <td>2406.73410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.339901919789828, 10.0, 22.708421284786994,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0001wb-05-12311</td>\n",
       "      <td>8.889443</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.074886</td>\n",
       "      <td>17.001041</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>her mantra &amp;quot;no more bad dates&amp;quot; is a ...</td>\n",
       "      <td>872.68384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[8.889443285070843, 5.0, 19.074885717934308, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1400tw-53-02910</td>\n",
       "      <td>7.796204</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.229402</td>\n",
       "      <td>15.395087</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>leave a comment in the past, i’ve had sex, i’v...</td>\n",
       "      <td>1970.16040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[7.796203967373771, 4.0, 17.22940189701382, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1801wb-11-09209</td>\n",
       "      <td>7.637733</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.292758</td>\n",
       "      <td>13.839917</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>nor can we make love without god for he is the...</td>\n",
       "      <td>1178.09250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[7.637732581490534, 4.0, 14.292757865862576, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno  score_pl2  score_tf   score_bm  score_dfic  \\\n",
       "0   1  clueweb12-0200wb-79-18105  11.626052       9.0  23.103274   21.680909   \n",
       "1   1  clueweb12-1214wb-88-29751  11.339902      10.0  22.708421   21.520754   \n",
       "2   1  clueweb12-0001wb-05-12311   8.889443       5.0  19.074886   17.001041   \n",
       "3   1  clueweb12-1400tw-53-02910   7.796204       4.0  17.229402   15.395087   \n",
       "4   1  clueweb12-1801wb-11-09209   7.637733       4.0  14.292758   13.839917   \n",
       "\n",
       "                                         query  \\\n",
       "0  what is the difference between sex and love   \n",
       "1  what is the difference between sex and love   \n",
       "2  what is the difference between sex and love   \n",
       "3  what is the difference between sex and love   \n",
       "4  what is the difference between sex and love   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  home &gt; articles &gt; sex, sexuality &amp; p...       2270.98270   \n",
       "1  sex may or may not include penetration. differ...       2406.73410   \n",
       "2  her mantra &quot;no more bad dates&quot; is a ...        872.68384   \n",
       "3  leave a comment in the past, i’ve had sex, i’v...       1970.16040   \n",
       "4  nor can we make love without god for he is the...       1178.09250   \n",
       "\n",
       "   is_retrieved  ap_score  objs_score  label  \\\n",
       "0           0.0       0.0         0.0      2   \n",
       "1           0.0       0.0         0.0      2   \n",
       "2           0.0       0.0         0.0      0   \n",
       "3           0.0       0.0         0.0      2   \n",
       "4           0.0       0.0         0.0      2   \n",
       "\n",
       "                                            features  \n",
       "0  [11.62605208595209, 9.0, 23.103273698299724, 2...  \n",
       "1  [11.339901919789828, 10.0, 22.708421284786994,...  \n",
       "2  [8.889443285070843, 5.0, 19.074885717934308, 1...  \n",
       "3  [7.796203967373771, 4.0, 17.22940189701382, 15...  \n",
       "4  [7.637732581490534, 4.0, 14.292757865862576, 1...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>score_bm</th>\n",
       "      <th>score_dfic</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "      <th>label_x</th>\n",
       "      <th>features</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>11.626052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.103274</td>\n",
       "      <td>21.680909</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>home &amp;gt; articles &amp;gt; sex, sexuality &amp;amp; p...</td>\n",
       "      <td>2270.98270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.62605208595209, 9.0, 23.103273698299724, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>11.339902</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.708421</td>\n",
       "      <td>21.520754</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>sex may or may not include penetration. differ...</td>\n",
       "      <td>2406.73410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.339901919789828, 10.0, 22.708421284786994,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0001wb-05-12311</td>\n",
       "      <td>8.889443</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.074886</td>\n",
       "      <td>17.001041</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>her mantra &amp;quot;no more bad dates&amp;quot; is a ...</td>\n",
       "      <td>872.68384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[8.889443285070843, 5.0, 19.074885717934308, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1400tw-53-02910</td>\n",
       "      <td>7.796204</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.229402</td>\n",
       "      <td>15.395087</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>leave a comment in the past, i’ve had sex, i’v...</td>\n",
       "      <td>1970.16040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[7.796203967373771, 4.0, 17.22940189701382, 15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1801wb-11-09209</td>\n",
       "      <td>7.637733</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.292758</td>\n",
       "      <td>13.839917</td>\n",
       "      <td>what is the difference between sex and love</td>\n",
       "      <td>nor can we make love without god for he is the...</td>\n",
       "      <td>1178.09250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[7.637732581490534, 4.0, 14.292757865862576, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno  score_pl2  score_tf   score_bm  score_dfic  \\\n",
       "0   1  clueweb12-0200wb-79-18105  11.626052       9.0  23.103274   21.680909   \n",
       "1   1  clueweb12-1214wb-88-29751  11.339902      10.0  22.708421   21.520754   \n",
       "2   1  clueweb12-0001wb-05-12311   8.889443       5.0  19.074886   17.001041   \n",
       "3   1  clueweb12-1400tw-53-02910   7.796204       4.0  17.229402   15.395087   \n",
       "4   1  clueweb12-1801wb-11-09209   7.637733       4.0  14.292758   13.839917   \n",
       "\n",
       "                                         query  \\\n",
       "0  what is the difference between sex and love   \n",
       "1  what is the difference between sex and love   \n",
       "2  what is the difference between sex and love   \n",
       "3  what is the difference between sex and love   \n",
       "4  what is the difference between sex and love   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  home &gt; articles &gt; sex, sexuality &amp; p...       2270.98270   \n",
       "1  sex may or may not include penetration. differ...       2406.73410   \n",
       "2  her mantra &quot;no more bad dates&quot; is a ...        872.68384   \n",
       "3  leave a comment in the past, i’ve had sex, i’v...       1970.16040   \n",
       "4  nor can we make love without god for he is the...       1178.09250   \n",
       "\n",
       "   is_retrieved  ap_score  objs_score  label_x  \\\n",
       "0           0.0       0.0         0.0        2   \n",
       "1           0.0       0.0         0.0        2   \n",
       "2           0.0       0.0         0.0        0   \n",
       "3           0.0       0.0         0.0        2   \n",
       "4           0.0       0.0         0.0        2   \n",
       "\n",
       "                                            features label_y  \n",
       "0  [11.62605208595209, 9.0, 23.103273698299724, 2...       0  \n",
       "1  [11.339901919789828, 10.0, 22.708421284786994,...       0  \n",
       "2  [8.889443285070843, 5.0, 19.074885717934308, 1...       0  \n",
       "3  [7.796203967373771, 4.0, 17.22940189701382, 15...       0  \n",
       "4  [7.637732581490534, 4.0, 14.292757865862576, 1...       0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>score_bm</th>\n",
       "      <th>score_dfic</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>baseline_scores</th>\n",
       "      <th>is_retrieved</th>\n",
       "      <th>ap_score</th>\n",
       "      <th>objs_score</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700tw-30-03487</td>\n",
       "      <td>6.597378</td>\n",
       "      <td>6.5</td>\n",
       "      <td>13.481996</td>\n",
       "      <td>13.584072</td>\n",
       "      <td>which operating system has better performance ...</td>\n",
       "      <td>windows 7 professional and ultimate users will...</td>\n",
       "      <td>2255.4893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.597377968911245, 6.5, 13.481995561686743, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0300tw-05-10074</td>\n",
       "      <td>6.555987</td>\n",
       "      <td>6.5</td>\n",
       "      <td>13.607904</td>\n",
       "      <td>13.723079</td>\n",
       "      <td>which operating system has better performance ...</td>\n",
       "      <td>windows 8 is a coin with two very different si...</td>\n",
       "      <td>1917.8842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.555986727741695, 6.5, 13.60790372983337, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1100tw-64-01206</td>\n",
       "      <td>5.987314</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.224987</td>\n",
       "      <td>11.186697</td>\n",
       "      <td>which operating system has better performance ...</td>\n",
       "      <td>it targeted even better performance for window...</td>\n",
       "      <td>1942.9227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5.987314476428924, 3.0, 13.224986571587602, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-0700tw-41-20357</td>\n",
       "      <td>5.911963</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.903069</td>\n",
       "      <td>12.959875</td>\n",
       "      <td>which operating system has better performance ...</td>\n",
       "      <td>microsoft&amp;#x27;s embedded windows operating sy...</td>\n",
       "      <td>2535.3645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.911962693211354, 8.0, 11.903069461047062, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>clueweb12-1700wb-29-15033</td>\n",
       "      <td>5.806860</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.168118</td>\n",
       "      <td>12.562240</td>\n",
       "      <td>which operating system has better performance ...</td>\n",
       "      <td>windows 8 improves on work on minwin which sta...</td>\n",
       "      <td>1950.5464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5.80685983863876, 8.0, 12.168117999890416, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno  score_pl2  score_tf   score_bm  score_dfic  \\\n",
       "0  40  clueweb12-1700tw-30-03487   6.597378       6.5  13.481996   13.584072   \n",
       "1  40  clueweb12-0300tw-05-10074   6.555987       6.5  13.607904   13.723079   \n",
       "2  40  clueweb12-1100tw-64-01206   5.987314       3.0  13.224987   11.186697   \n",
       "3  40  clueweb12-0700tw-41-20357   5.911963       8.0  11.903069   12.959875   \n",
       "4  40  clueweb12-1700wb-29-15033   5.806860       8.0  12.168118   12.562240   \n",
       "\n",
       "                                               query  \\\n",
       "0  which operating system has better performance ...   \n",
       "1  which operating system has better performance ...   \n",
       "2  which operating system has better performance ...   \n",
       "3  which operating system has better performance ...   \n",
       "4  which operating system has better performance ...   \n",
       "\n",
       "                                                text  baseline_scores  \\\n",
       "0  windows 7 professional and ultimate users will...        2255.4893   \n",
       "1  windows 8 is a coin with two very different si...        1917.8842   \n",
       "2  it targeted even better performance for window...        1942.9227   \n",
       "3  microsoft&#x27;s embedded windows operating sy...        2535.3645   \n",
       "4  windows 8 improves on work on minwin which sta...        1950.5464   \n",
       "\n",
       "   is_retrieved  ap_score  objs_score label  \\\n",
       "0           1.0       0.0         2.0     0   \n",
       "1           1.0       0.0         2.0     1   \n",
       "2           1.0       1.0         2.0     2   \n",
       "3           1.0       0.0         2.0     0   \n",
       "4           1.0       0.0         2.0     2   \n",
       "\n",
       "                                            features  \n",
       "0  [6.597377968911245, 6.5, 13.481995561686743, 1...  \n",
       "1  [6.555986727741695, 6.5, 13.60790372983337, 13...  \n",
       "2  [5.987314476428924, 3.0, 13.224986571587602, 1...  \n",
       "3  [5.911962693211354, 8.0, 11.903069461047062, 1...  \n",
       "4  [5.80685983863876, 8.0, 12.168117999890416, 12...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
