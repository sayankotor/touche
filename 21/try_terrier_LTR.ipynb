{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "PyTerrier 0.5.0 has loaded Terrier 5.4 (built by craigm on 2021-01-16 14:17)\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  print (\"not\")  \n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade fastrank lightgbm \n",
    "#!pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<DOM Element: topics at 0x7f074a03f550>]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from baseline import read_xml\n",
    "topics_2020 = read_xml('topics-task-2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('46', '\\nWhich beverage has more calories per glass: beer or cider?\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_2020[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#r = requests.post('http://10.30.99.211:8261/gpt_small', data = \"What is better for deep learning Python or Matlab?\")\n",
    "#print (r.status_code)\n",
    "import requests\n",
    "from xml.dom import minidom\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>topics</th>\n",
       "      <th>topics_lang</th>\n",
       "      <th>qrels</th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus_lang</th>\n",
       "      <th>index</th>\n",
       "      <th>info_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50pct</td>\n",
       "      <td>[training, validation]</td>\n",
       "      <td>en</td>\n",
       "      <td>[training, validation]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ex1, ex2]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antique</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>en</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ciir.cs.umass.edu/downloads/Antique/re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vaswani</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>http://ir.dcs.gla.ac.uk/resources/test_collect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trec-deep-learning-docs</td>\n",
       "      <td>[train, dev, test, test-2020, leaderboard-2020]</td>\n",
       "      <td>en</td>\n",
       "      <td>[train, dev, test, test-2020]</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://microsoft.github.io/msmarco/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trec-deep-learning-passages</td>\n",
       "      <td>[train, dev, eval, test-2019, test-2020]</td>\n",
       "      <td>en</td>\n",
       "      <td>[train, dev, test-2019, test-2020]</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://microsoft.github.io/MSMARCO-Passage-Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>irds:wikir/en1k/validation</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ir-datasets.com/wikir.html#wikir/en1k/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>irds:wikir/en59k</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ir-datasets.com/wikir.html#wikir/en59k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>irds:wikir/en59k/test</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ir-datasets.com/wikir.html#wikir/en59k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>irds:wikir/en59k/training</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ir-datasets.com/wikir.html#wikir/en59k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>irds:wikir/en59k/validation</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>https://ir-datasets.com/wikir.html#wikir/en59k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dataset  \\\n",
       "0                          50pct   \n",
       "1                        antique   \n",
       "2                        vaswani   \n",
       "3        trec-deep-learning-docs   \n",
       "4    trec-deep-learning-passages   \n",
       "..                           ...   \n",
       "195   irds:wikir/en1k/validation   \n",
       "196             irds:wikir/en59k   \n",
       "197        irds:wikir/en59k/test   \n",
       "198    irds:wikir/en59k/training   \n",
       "199  irds:wikir/en59k/validation   \n",
       "\n",
       "                                              topics topics_lang  \\\n",
       "0                             [training, validation]          en   \n",
       "1                                      [train, test]          en   \n",
       "2                                               True          en   \n",
       "3    [train, dev, test, test-2020, leaderboard-2020]          en   \n",
       "4           [train, dev, eval, test-2019, test-2020]          en   \n",
       "..                                               ...         ...   \n",
       "195                                             True          en   \n",
       "196                                             None        None   \n",
       "197                                             True          en   \n",
       "198                                             True          en   \n",
       "199                                             True          en   \n",
       "\n",
       "                                  qrels corpus corpus_lang       index  \\\n",
       "0                [training, validation]   None        None  [ex1, ex2]   \n",
       "1                         [train, test]   True          en        None   \n",
       "2                                  True   True          en        True   \n",
       "3         [train, dev, test, test-2020]   True          en        None   \n",
       "4    [train, dev, test-2019, test-2020]   True          en        None   \n",
       "..                                  ...    ...         ...         ...   \n",
       "195                                True   True          en        None   \n",
       "196                                None   True          en        None   \n",
       "197                                True   True          en        None   \n",
       "198                                True   True          en        None   \n",
       "199                                True   True          en        None   \n",
       "\n",
       "                                              info_url  \n",
       "0                                                 None  \n",
       "1    https://ciir.cs.umass.edu/downloads/Antique/re...  \n",
       "2    http://ir.dcs.gla.ac.uk/resources/test_collect...  \n",
       "3                 https://microsoft.github.io/msmarco/  \n",
       "4    https://microsoft.github.io/MSMARCO-Passage-Ra...  \n",
       "..                                                 ...  \n",
       "195  https://ir-datasets.com/wikir.html#wikir/en1k/...  \n",
       "196     https://ir-datasets.com/wikir.html#wikir/en59k  \n",
       "197  https://ir-datasets.com/wikir.html#wikir/en59k...  \n",
       "198  https://ir-datasets.com/wikir.html#wikir/en59k...  \n",
       "199  https://ir-datasets.com/wikir.html#wikir/en59k...  \n",
       "\n",
       "[165 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.datasets.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read retireved documents and qrels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('/notebook/touche/list_of_un_answ.pkl', 'rb') as f:\n",
    "    answers_2020 = pickle.load(f)\n",
    "    \n",
    "with open('/notebook/touche2021/touche2020-task2-relevance-withbaseline.qrels', 'r') as f:\n",
    "    qrels_lines = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "qrels = [x.strip().split() for x in qrels_lines] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create qrels dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "for elem in qrels:\n",
    "    query, noninf, docno, rank = elem\n",
    "    if (query in qrels_dict.keys()):\n",
    "        qrels_dict[query].append((docno, rank))\n",
    "    else:\n",
    "        qrels_dict[query] = []\n",
    "        qrels_dict[query].append((docno, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clueweb12-1715wb-31-22014', '0'),\n",
       " ('clueweb12-0106wb-15-00715', '0'),\n",
       " ('clueweb12-1313wb-74-02250', '0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_dict['46'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1644.429,\n",
       " 'clueweb12-1002wb-27-05922',\n",
       " 'pca beverage 101 - beer',\n",
       " 'the finest ciders in north america may well emanate from the province of quebec in canada, which has an established artisinal cider industry with historical ties to normandy cider. these quebecois ciders are slowly starting to appear on the us market. herb-spiced and fruit beers.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_2020['46'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create proper pandas df documents and qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'object' has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e8a7c1796120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minfo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"docno\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minfo_df_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"docno\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqrels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"docno\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mnan_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_arraylike_from_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mconstruct_1d_arraylike_from_scalar\u001b[0;34m(value, length, dtype)\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'object' has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "info_df = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\",\"label\"])\n",
    "info_df_test = pd.DataFrame(columns=[\"qid\", \"query\", \"docno\", \"text\", \"label\"])\n",
    "qrels_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"])\n",
    "qrels_df_test = pd.DataFrame(columns=[\"qid\", \"docno\", \"label\"])\n",
    "\n",
    "for elem in topics_2020:\n",
    "    qid, query = elem[0], elem[1].strip('\\n')\n",
    "    query = re.sub(r'[^\\w\\s]','',query)\n",
    "    qrels = qrels_dict[qid]\n",
    "    for ind, answer in enumerate(answers_2020[qid]):\n",
    "        #docno1, label = qrels[ind]\n",
    "        docno = answer[1]\n",
    "        score = answer[0]\n",
    "        text = answer[3]\n",
    "        label = [el[1] for el in qrels if el[0]==docno]\n",
    "        \n",
    "        if (int(qid) < 40 and len(label) > 0):\n",
    "            df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"text\":text, \"label\": label[0]}\n",
    "            info_df = info_df.append(df_row, ignore_index= True)\n",
    "        else:\n",
    "            info_df_test = info_df_test.append(df_row, ignore_index= True)\n",
    "            \n",
    "    for qrel in qrels_dict[qid]:\n",
    "        docno, label = qrel\n",
    "        df_row = {\"qid\":qid, \"query\":query, \"docno\":docno, \"labels\":label}\n",
    "        if (int(qid) < 40):\n",
    "            qrels_df = qrels_df.append(df_row, ignore_index= True)\n",
    "        else:\n",
    "            qrels_df_test = qrels_df_test.append(df_row, ignore_index= True)\n",
    "            \n",
    "\n",
    "\n",
    "#textscorerTf = pt.text.scorer(body_attr=\"text\", wmodel=\"Tf\")\n",
    "#rtr = textscorerTf.transform("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120 1367\n"
     ]
    }
   ],
   "source": [
    "print(len(info_df),len(qrels_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.text import scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['labels'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-310179249140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#test_ds = create_featured_dataset(info_df_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_featured_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-310179249140>\u001b[0m in \u001b[0;36mcreate_featured_dataset\u001b[0;34m(some_df)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrtr_dfic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextscorerTf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrtr_pl2_for_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtr_pl2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'docno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mrtr_pl2_for_merge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtr_pl2_for_merge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"score_pl2\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['labels'] not in index\""
     ]
    }
   ],
   "source": [
    "def create_featured_dataset(some_df):\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='BM25')\n",
    "    rtr_bm = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='Tf')\n",
    "    rtr_tf = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='PL2')\n",
    "    rtr_pl2 = textscorerTf.transform(some_df)\n",
    "    textscorerTf = text.scorer(body_attr=\"text\", wmodel='DFIC')\n",
    "    rtr_dfic = textscorerTf.transform(some_df)\n",
    "    \n",
    "    rtr_pl2_for_merge = rtr_pl2[['qid', 'docno', 'score', 'labels']]\n",
    "    rtr_pl2_for_merge = rtr_pl2_for_merge.rename(columns={\"score\": \"score_pl2\"})\n",
    "    \n",
    "    rtr_tf_for_merge = rtr_tf[['qid', 'docno', 'score', 'labels']]\n",
    "    rtr_tf_for_merge = rtr_tf_for_merge.rename(columns={\"score\": \"score_tf\"})\n",
    "    \n",
    "    rtr_bm_for_merge = rtr_bm[['qid', 'docno', 'score','labels']]\n",
    "    rtr_bm_for_merge = rtr_bm_for_merge.rename(columns={\"score\": \"score_bm\"})\n",
    "    \n",
    "    rtr_dfic_for_merge = rtr_dfic[['qid', 'docno', 'score','labels']]\n",
    "    rtr_dfic_for_merge = rtr_dfic_for_merge.rename(columns={\"score\": \"score_dfic\"})\n",
    "    \n",
    "    result = pd.merge(rtr_pl2_for_merge, rtr_tf_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_bm_for_merge, on=[\"qid\", \"docno\"])\n",
    "    result = pd.merge(result, rtr_dfic_for_merge, on=[\"qid\", \"docno\"])\n",
    "    zipped = [result[\"score_pl2\"], result[\"score_tf\"], result[\"score_bm\"], result[\"score_dfic\"]]\n",
    "    unzipped_object = zip(*zipped)\n",
    "    unzipped_list = list(unzipped_object)\n",
    "    list_of_features = [np.array(elem) for elem in unzipped_list]\n",
    "    result['features'] = list_of_features\n",
    "    return result\n",
    "\n",
    "#test_ds = create_featured_dataset(info_df_test)\n",
    "result = create_featured_dataset(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking with LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1412wb-36-28142</td>\n",
       "      <td>0</td>\n",
       "      <td>23.759399</td>\n",
       "      <td>What is the difference between sex and love</td>\n",
       "      <td>12.226873</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(12.226872811709208, 8.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>1</td>\n",
       "      <td>23.572710</td>\n",
       "      <td>What is the difference between sex and love</td>\n",
       "      <td>12.389736</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(12.38973604711742, 9.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>2</td>\n",
       "      <td>23.162551</td>\n",
       "      <td>What is the difference between sex and love</td>\n",
       "      <td>12.102459</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(12.102459029367102, 10.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0601wb-52-24897</td>\n",
       "      <td>3</td>\n",
       "      <td>21.569264</td>\n",
       "      <td>What is the difference between sex and love</td>\n",
       "      <td>10.757675</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(10.757674893691874, 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0706wb-92-20025</td>\n",
       "      <td>4</td>\n",
       "      <td>21.569264</td>\n",
       "      <td>What is the difference between sex and love</td>\n",
       "      <td>10.757675</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(10.757674893691874, 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30986</th>\n",
       "      <td>39</td>\n",
       "      <td>clueweb12-0814wb-82-11198</td>\n",
       "      <td>949</td>\n",
       "      <td>5.294241</td>\n",
       "      <td>Is Java code more readable than code written i...</td>\n",
       "      <td>2.455748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.4557475851450614, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30987</th>\n",
       "      <td>39</td>\n",
       "      <td>clueweb12-0909wb-01-06662</td>\n",
       "      <td>968</td>\n",
       "      <td>5.187425</td>\n",
       "      <td>Is Java code more readable than code written i...</td>\n",
       "      <td>2.397503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.3975030894290374, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30988</th>\n",
       "      <td>39</td>\n",
       "      <td>clueweb12-1616wb-95-21533</td>\n",
       "      <td>978</td>\n",
       "      <td>5.084834</td>\n",
       "      <td>Is Java code more readable than code written i...</td>\n",
       "      <td>2.341928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.3419282603846416, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30989</th>\n",
       "      <td>39</td>\n",
       "      <td>clueweb12-0606wb-13-09259</td>\n",
       "      <td>989</td>\n",
       "      <td>5.084834</td>\n",
       "      <td>Is Java code more readable than code written i...</td>\n",
       "      <td>2.341928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.3419282603846416, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30990</th>\n",
       "      <td>39</td>\n",
       "      <td>clueweb12-1102wb-40-13283</td>\n",
       "      <td>995</td>\n",
       "      <td>4.986223</td>\n",
       "      <td>Is Java code more readable than code written i...</td>\n",
       "      <td>2.288811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2.2888111588797777, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30991 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qid                      docno  rank      score  \\\n",
       "0       1  clueweb12-1412wb-36-28142     0  23.759399   \n",
       "1       1  clueweb12-0200wb-79-18105     1  23.572710   \n",
       "2       1  clueweb12-1214wb-88-29751     2  23.162551   \n",
       "3       1  clueweb12-0601wb-52-24897     3  21.569264   \n",
       "4       1  clueweb12-0706wb-92-20025     4  21.569264   \n",
       "...    ..                        ...   ...        ...   \n",
       "30986  39  clueweb12-0814wb-82-11198   949   5.294241   \n",
       "30987  39  clueweb12-0909wb-01-06662   968   5.187425   \n",
       "30988  39  clueweb12-1616wb-95-21533   978   5.084834   \n",
       "30989  39  clueweb12-0606wb-13-09259   989   5.084834   \n",
       "30990  39  clueweb12-1102wb-40-13283   995   4.986223   \n",
       "\n",
       "                                                   query  score_pl2  score_tf  \\\n",
       "0            What is the difference between sex and love  12.226873       8.0   \n",
       "1            What is the difference between sex and love  12.389736       9.0   \n",
       "2            What is the difference between sex and love  12.102459      10.0   \n",
       "3            What is the difference between sex and love  10.757675       6.0   \n",
       "4            What is the difference between sex and love  10.757675       6.0   \n",
       "...                                                  ...        ...       ...   \n",
       "30986  Is Java code more readable than code written i...   2.455748       1.0   \n",
       "30987  Is Java code more readable than code written i...   2.397503       1.0   \n",
       "30988  Is Java code more readable than code written i...   2.341928       1.0   \n",
       "30989  Is Java code more readable than code written i...   2.341928       1.0   \n",
       "30990  Is Java code more readable than code written i...   2.288811       1.0   \n",
       "\n",
       "                         features  \n",
       "0       (12.226872811709208, 8.0)  \n",
       "1        (12.38973604711742, 9.0)  \n",
       "2      (12.102459029367102, 10.0)  \n",
       "3       (10.757674893691874, 6.0)  \n",
       "4       (10.757674893691874, 6.0)  \n",
       "...                           ...  \n",
       "30986   (2.4557475851450614, 1.0)  \n",
       "30987   (2.3975030894290374, 1.0)  \n",
       "30988   (2.3419282603846416, 1.0)  \n",
       "30989   (2.3419282603846416, 1.0)  \n",
       "30990   (2.2888111588797777, 1.0)  \n",
       "\n",
       "[30991 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, elem in enumerate[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0001wb-05-12311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1217wb-47-14048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1811wb-62-08425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno label\n",
       "0   1  clueweb12-0001wb-05-12311     0\n",
       "1   1  clueweb12-1811wb-62-08424     1\n",
       "2   1  clueweb12-1811wb-62-08423     1\n",
       "3   1  clueweb12-1217wb-47-14048     0\n",
       "4   1  clueweb12-1811wb-62-08425     1"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>score_pl2</th>\n",
       "      <th>score_tf</th>\n",
       "      <th>score_bm</th>\n",
       "      <th>score_dfic</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0200wb-79-18105</td>\n",
       "      <td>13.061090</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.543436</td>\n",
       "      <td>23.535107</td>\n",
       "      <td>[13.061089692931793, 9.0, 25.543435870477545, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1214wb-88-29751</td>\n",
       "      <td>12.789944</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.162405</td>\n",
       "      <td>23.377776</td>\n",
       "      <td>[12.789944043049017, 10.0, 25.16240459131109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0706wb-92-20025</td>\n",
       "      <td>11.361396</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.349389</td>\n",
       "      <td>20.876798</td>\n",
       "      <td>[11.361395517783325, 6.0, 23.349388700158293, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-1400tw-53-02910</td>\n",
       "      <td>8.915299</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.236397</td>\n",
       "      <td>17.269851</td>\n",
       "      <td>[8.915298882242885, 4.0, 19.236396596096135, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>clueweb12-0406wb-58-08558</td>\n",
       "      <td>8.753663</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.078806</td>\n",
       "      <td>16.233385</td>\n",
       "      <td>[8.753663308642151, 5.0, 18.07880589092797, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                      docno  score_pl2  score_tf   score_bm  score_dfic  \\\n",
       "0   1  clueweb12-0200wb-79-18105  13.061090       9.0  25.543436   23.535107   \n",
       "1   1  clueweb12-1214wb-88-29751  12.789944      10.0  25.162405   23.377776   \n",
       "2   1  clueweb12-0706wb-92-20025  11.361396       6.0  23.349389   20.876798   \n",
       "3   1  clueweb12-1400tw-53-02910   8.915299       4.0  19.236397   17.269851   \n",
       "4   1  clueweb12-0406wb-58-08558   8.753663       5.0  18.078806   16.233385   \n",
       "\n",
       "                                            features  \n",
       "0  [13.061089692931793, 9.0, 25.543435870477545, ...  \n",
       "1  [12.789944043049017, 10.0, 25.16240459131109, ...  \n",
       "2  [11.361395517783325, 6.0, 23.349388700158293, ...  \n",
       "3  [8.915298882242885, 4.0, 19.236396596096135, 1...  \n",
       "4  [8.753663308642151, 5.0, 18.07880589092797, 16...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "#tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "#pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "#pipeline = (rtr_tf ** rtr_pl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranks1(rtr : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Canonical method for adding a rank column which is calculated based on the score attribute\n",
    "        for each query. Note that the dataframe is NOT sorted by this operation.\n",
    "        Arguments\n",
    "            df: dataframe to create rank attribute for\n",
    "    \"\"\"\n",
    "    rtr.drop(columns=[\"rank\"], errors=\"ignore\", inplace=True)\n",
    "    if len(rtr) == 0:\n",
    "        rtr[\"rank\"] = pd.Series(index=rtr.index, dtype='int64')\n",
    "        return rtr\n",
    "    print (0)\n",
    "    # -1 assures that first rank will be FIRST_RANK\n",
    "    rtr[\"rank\"] = rtr.groupby(\"qid\", sort=False)[\"score\"].rank(ascending=False, method=\"first\").astype(int) -1 + 1\n",
    "    print (1)\n",
    "    if True:\n",
    "        rtr.sort_values([\"qid\", \"rank\"], ascending=[True,True], inplace=True)\n",
    "    return rtr\n",
    "\n",
    "def transform(model, test_DF):\n",
    "    \"\"\"\n",
    "    Predicts the scores for the given topics.\n",
    "\n",
    "    Args:\n",
    "        topicsTest(DataFrame): A dataframe with the test topics.\n",
    "    \"\"\"\n",
    "    test_DF = test_DF.copy()\n",
    "\n",
    "    # check for change in number of features\n",
    "    found_numf = test_DF.iloc[0].features.shape[0]\n",
    "    if model.num_f is not None:\n",
    "        if found_numf != model.num_f:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (model.num_f, found_numf))\n",
    "    if hasattr(model.learner, 'feature_importances_'):\n",
    "        if len(model.learner.feature_importances_) != found_numf:\n",
    "            raise ValueError(\"Expected %d features, but found %d features\" % (len(model.learner.feature_importances_), found_numf))\n",
    "\n",
    "    test_DF[\"score\"] = model.learner.predict(np.stack(test_DF[\"features\"].values))\n",
    "    return add_ranks1(test_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d0d551c887df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mansw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'answ' is not defined"
     ]
    }
   ],
   "source": [
    "answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf_pipe = pt.ltr.apply_learned_model(rf)\n",
    "rf_pipe.fit(result, qrels_df)\n",
    "answs = transform(rf_pipe, result)\n",
    "#pt.Experiment([result, rf_pipe], result, qrels_df, [\"map\"], names=[\"BM25 Baseline\", \"LTR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qrels(name, rtr):\n",
    "    qids = rtr['qid']\n",
    "    Q0s = [0 for elem in qids]\n",
    "    docs = rtr['docno']\n",
    "    scores = rtr['score']\n",
    "    ranks = rtr['rank']\n",
    "    tags = [name for elem in qids]\n",
    "    common_list = list(zip(qids, Q0s, docs, ranks, scores, tags))\n",
    "    with open(name +'.qrels', 'w') as fp:\n",
    "        fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in common_list))\n",
    "    print (\"written \" + name +'.qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written RF.qrels\n"
     ]
    }
   ],
   "source": [
    "write_qrels(\"RF\", answs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading antique topics to /root/.pyterrier/corpora/antique/antique-train-queries.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "antique-train-queries.txt: 100%|██████████| 133k/133k [00:00<00:00, 250kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3097310</td>\n",
       "      <td>what causes severe swelling and pain in the knees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3910705</td>\n",
       "      <td>why don t they put parachutes underneath airpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237390</td>\n",
       "      <td>how to clean alloy cylinder heads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2247892</td>\n",
       "      <td>how do i get them whiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078492</td>\n",
       "      <td>what is cloud 9 and 7th heaven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                                              query\n",
       "0  3097310  what causes severe swelling and pain in the knees\n",
       "1  3910705  why don t they put parachutes underneath airpl...\n",
       "2   237390                  how to clean alloy cylinder heads\n",
       "3  2247892                           how do i get them whiter\n",
       "4  1078492                     what is cloud 9 and 7th heaven"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19.get_topics(variant='train').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labels'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-4c62e473518d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "result['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Should set group for ranking task",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9bd913e67651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrf_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_learned_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmart_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrf_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrels_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mansws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pyterrier/ltr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, topics_and_results_Train, qrelsTrain, topics_and_results_Valid, qrelsValid)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtrain_DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopics_and_results_Train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqrelsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'docno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# check group data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Should set group for ranking task\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Should set group for ranking task"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "rf_pipe = pt.ltr.apply_learned_model(lmart_l)\n",
    "rf_pipe.fit(result, qrels_df)\n",
    "answs = transform(rf_pipe, result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
